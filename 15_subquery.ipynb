{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e7d10f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/10 14:54:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/12/10 14:54:04 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('SparkSQL-Execution-Plan').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1451754e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "dept_df = spark.read.format('csv')\\\n",
    "                .option('header','true')\\\n",
    "                .option('inferSchema', 'true')\\\n",
    "                .load('data/dept.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0e72177",
   "metadata": {},
   "outputs": [],
   "source": [
    "dept_df.createOrReplaceTempView('dept_df_view')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "161021e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_df = spark.read.format('csv')\\\n",
    "                .option('header','true')\\\n",
    "                .option('inferSchema', 'true')\\\n",
    "                .load('data/emp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9546b4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_df.createOrReplaceTempView('emp_df_view')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c25f15",
   "metadata": {},
   "source": [
    "## 조인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40430392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---------+----+----------+----+----+------+------+----------+--------+\n",
      "|empno| ename|      job| mgr|  hiredate| sal|comm|deptno|deptno|     dname|     loc|\n",
      "+-----+------+---------+----+----------+----+----+------+------+----------+--------+\n",
      "| 7369| SMITH|    CLERK|7902|1980-12-17| 800|null|    20|    20|  RESEARCH|  DALLAS|\n",
      "| 7499| ALLEN| SALESMAN|7698|1981-02-20|1600| 300|    30|    30|     SALES| CHICAGO|\n",
      "| 7521|  WARD| SALESMAN|7698|1981-02-22|1250| 500|    30|    30|     SALES| CHICAGO|\n",
      "| 7566| JONES|  MANAGER|7839|1981-04-02|2975|null|    20|    20|  RESEARCH|  DALLAS|\n",
      "| 7654|MARTIN| SALESMAN|7698|1981-09-28|1250|1400|    30|    30|     SALES| CHICAGO|\n",
      "| 7698| BLAKE|  MANAGER|7839|1981-05-01|2850|null|    30|    30|     SALES| CHICAGO|\n",
      "| 7782| CLARK|  MANAGER|7839|1981-06-09|2450|null|    10|    10|ACCOUNTING|NEW YORK|\n",
      "| 7788| SCOTT|  ANALYST|7566|1987-04-19|3000|null|    20|    20|  RESEARCH|  DALLAS|\n",
      "| 7839|  KING|PRESIDENT|null|1981-11-17|5000|null|    10|    10|ACCOUNTING|NEW YORK|\n",
      "| 7844|TURNER| SALESMAN|7698|1981-09-08|1500|   0|    30|    30|     SALES| CHICAGO|\n",
      "| 7876| ADAMS|    CLERK|7788|1987-05-23|1100|null|    20|    20|  RESEARCH|  DALLAS|\n",
      "| 7900| JAMES|    CLERK|7698|1981-12-03| 950|null|    30|    30|     SALES| CHICAGO|\n",
      "| 7902|  FORD|  ANALYST|7566|1981-12-03|3000|null|    20|    20|  RESEARCH|  DALLAS|\n",
      "| 7934|MILLER|    CLERK|7782|1982-01-23|1300|null|    10|    10|ACCOUNTING|NEW YORK|\n",
      "+-----+------+---------+----+----------+----+----+------+------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = '''\n",
    "select * \n",
    "from emp_df_view\n",
    "join dept_df_view\n",
    "on emp_df_view.deptno = dept_df_view.deptno\n",
    "'''\n",
    "\n",
    "viewEmpDept = spark.sql(query)\n",
    "viewEmpDept.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e15005",
   "metadata": {},
   "source": [
    "## 부서위치가 NEW YORK인 직원 목록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "404f66a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---------+----+----------+----+----+------+------+----------+--------+\n",
      "|empno| ename|      job| mgr|  hiredate| sal|comm|deptno|deptno|     dname|     loc|\n",
      "+-----+------+---------+----+----------+----+----+------+------+----------+--------+\n",
      "| 7782| CLARK|  MANAGER|7839|1981-06-09|2450|null|    10|    10|ACCOUNTING|NEW YORK|\n",
      "| 7839|  KING|PRESIDENT|null|1981-11-17|5000|null|    10|    10|ACCOUNTING|NEW YORK|\n",
      "| 7934|MILLER|    CLERK|7782|1982-01-23|1300|null|    10|    10|ACCOUNTING|NEW YORK|\n",
      "+-----+------+---------+----+----------+----+----+------+------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "viewEmpDept.createOrReplaceTempView('viewEmpDept')\n",
    "\n",
    "query = '''\n",
    "select *\n",
    "from viewEmpDept\n",
    "where loc = 'NEW YORK'\n",
    "'''\n",
    "\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b8e6b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(2) BroadcastHashJoin [deptno#45], [deptno#16], Inner, BuildRight, false\n",
      ":- *(2) Filter isnotnull(deptno#45)\n",
      ":  +- FileScan csv [empno#38,ename#39,job#40,mgr#41,hiredate#42,sal#43,comm#44,deptno#45] Batched: false, DataFilters: [isnotnull(deptno#45)], Format: CSV, Location: InMemoryFileIndex[file:/home/lab11/src/data/emp.csv], PartitionFilters: [], PushedFilters: [IsNotNull(deptno)], ReadSchema: struct<empno:int,ename:string,job:string,mgr:int,hiredate:string,sal:int,comm:int,deptno:int>\n",
      "+- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [id=#257]\n",
      "   +- *(1) Filter ((isnotnull(loc#18) AND (loc#18 = NEW YORK)) AND isnotnull(deptno#16))\n",
      "      +- FileScan csv [deptno#16,dname#17,loc#18] Batched: false, DataFilters: [isnotnull(loc#18), (loc#18 = NEW YORK), isnotnull(deptno#16)], Format: CSV, Location: InMemoryFileIndex[file:/home/lab11/src/data/dept.csv], PartitionFilters: [], PushedFilters: [IsNotNull(loc), EqualTo(loc,NEW YORK), IsNotNull(deptno)], ReadSchema: struct<deptno:int,dname:string,loc:string>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 실행계획\n",
    "spark.sql(query).explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1bb177",
   "metadata": {},
   "source": [
    "## 서브쿼리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24a7591f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---------+----+----------+----+----+------+\n",
      "|empno| ename|      job| mgr|  hiredate| sal|comm|deptno|\n",
      "+-----+------+---------+----+----------+----+----+------+\n",
      "| 7782| CLARK|  MANAGER|7839|1981-06-09|2450|null|    10|\n",
      "| 7839|  KING|PRESIDENT|null|1981-11-17|5000|null|    10|\n",
      "| 7934|MILLER|    CLERK|7782|1982-01-23|1300|null|    10|\n",
      "+-----+------+---------+----+----------+----+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = '''\n",
    "select *\n",
    "from emp_df_view\n",
    "where deptno = (\n",
    "    select deptno\n",
    "    from dept_df_view\n",
    "    where loc='NEW YORK')\n",
    "'''\n",
    "\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8785dc9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(1) Filter (isnotnull(deptno#45) AND (deptno#45 = Subquery scalar-subquery#240, [id=#177]))\n",
      ":  +- Subquery scalar-subquery#240, [id=#177]\n",
      ":     +- *(1) Project [deptno#16]\n",
      ":        +- *(1) Filter (isnotnull(loc#18) AND (loc#18 = NEW YORK))\n",
      ":           +- FileScan csv [deptno#16,loc#18] Batched: false, DataFilters: [isnotnull(loc#18), (loc#18 = NEW YORK)], Format: CSV, Location: InMemoryFileIndex[file:/home/lab11/src/data/dept.csv], PartitionFilters: [], PushedFilters: [IsNotNull(loc), EqualTo(loc,NEW YORK)], ReadSchema: struct<deptno:int,loc:string>\n",
      "+- FileScan csv [empno#38,ename#39,job#40,mgr#41,hiredate#42,sal#43,comm#44,deptno#45] Batched: false, DataFilters: [isnotnull(deptno#45)], Format: CSV, Location: InMemoryFileIndex[file:/home/lab11/src/data/emp.csv], PartitionFilters: [], PushedFilters: [IsNotNull(deptno)], ReadSchema: struct<empno:int,ename:string,job:string,mgr:int,hiredate:string,sal:int,comm:int,deptno:int>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 실행계획\n",
    "spark.sql(query).explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f167fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (spark_start)",
   "language": "python",
   "name": "spark_start"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
