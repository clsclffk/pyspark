{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8057ab6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/11 10:28:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('Book-User').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb152f40",
   "metadata": {},
   "source": [
    "## books, users 테이블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3313755c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "books_data = [\n",
    "    Row(book_id=1, title=\"Book A\", author_fname=\"John\", author_lname=\"Doe\", pages=300, released_year=2005, stock_quantity=55),\n",
    "    Row(book_id=2, title=\"Book B\", author_fname=\"Jane\", author_lname=\"Smith\", pages=250, released_year=2010, stock_quantity=40),\n",
    "    Row(book_id=3, title=\"Book C\", author_fname=\"Emily\", author_lname=\"Jones\", pages=180, released_year=2015, stock_quantity=20),\n",
    "    Row(book_id=4, title=\"Book D\", author_fname=\"Chris\", author_lname=\"Brown\", pages=320, released_year=2012, stock_quantity=75),\n",
    "    Row(book_id=5, title=\"Book E\", author_fname=\"Anna\", author_lname=\"Davis\", pages=270, released_year=2008, stock_quantity=35)\n",
    "]\n",
    "\n",
    "users_data = [\n",
    "    Row(user_id=1, username='A', address='서울'),\n",
    "    Row(user_id=2, username='B', address='대전'),\n",
    "    Row(user_id=3, username='C', address='경기도'),\n",
    "    Row(user_id=4, username='D', address=None),\n",
    "    Row(user_id=5, username='E', address=None),\n",
    "    Row(user_id=6, username='F', address='서울'),\n",
    "    Row(user_id=7, username='G', address='경기도'),\n",
    "    Row(user_id=8, username='H', address='대구'),\n",
    "    Row(user_id=9, username='I', address='부산'),\n",
    "    Row(user_id=10, username='J', address='전주'),\n",
    "    Row(user_id=11, username='K', address='광주')\n",
    "]\n",
    "\n",
    "books_df = spark.createDataFrame(books_data)\n",
    "users_df = spark.createDataFrame(users_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1912f691",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------------+------------+-----+-------------+--------------+\n",
      "|book_id| title|author_fname|author_lname|pages|released_year|stock_quantity|\n",
      "+-------+------+------------+------------+-----+-------------+--------------+\n",
      "|      1|Book A|        John|         Doe|  300|         2005|            55|\n",
      "+-------+------+------------+------------+-----+-------------+--------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "books_df.createOrReplaceTempView(\"books\")\n",
    "users_df.createOrReplaceTempView(\"users\")\n",
    "\n",
    "spark.sql('select * from books where released_year=2005').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87b07c4",
   "metadata": {},
   "source": [
    "## SELECT 문에서 조건식 사용\n",
    "\n",
    "```\n",
    "IF(condition, true_value, false_value)\n",
    "```\n",
    "\n",
    "```SELECT\n",
    "    CASE column_name\n",
    "        WHEN value1 THEN result1\n",
    "        WHEN value2 THEN result2\n",
    "        ELSE default_value\n",
    "    END AS result\n",
    "FROM table_name;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5509fe15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|address|is_null|\n",
      "+-------+-------+\n",
      "|   서울|  false|\n",
      "|   대전|  false|\n",
      "| 경기도|  false|\n",
      "|   null|   true|\n",
      "|   null|   true|\n",
      "|   서울|  false|\n",
      "| 경기도|  false|\n",
      "|   대구|  false|\n",
      "|   부산|  false|\n",
      "|   전주|  false|\n",
      "|   광주|  false|\n",
      "+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select address, address is Null as is_null from users').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b61709ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+\n",
      "|username| address|\n",
      "+--------+--------+\n",
      "|       A|    서울|\n",
      "|       B|    대전|\n",
      "|       C|  경기도|\n",
      "|       D|주소없음|\n",
      "|       E|주소없음|\n",
      "|       F|    서울|\n",
      "|       G|  경기도|\n",
      "|       H|    대구|\n",
      "|       I|    부산|\n",
      "|       J|    전주|\n",
      "|       K|    광주|\n",
      "+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = '''\n",
    "select username,\n",
    "    if (address is null, '주소없음', address) as address\n",
    "from users\n",
    "'''\n",
    "\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f02ef5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|address|region|\n",
      "+-------+------+\n",
      "|   서울|수도권|\n",
      "|   대전|  지방|\n",
      "| 경기도|수도권|\n",
      "|   null|  지방|\n",
      "|   null|  지방|\n",
      "|   서울|수도권|\n",
      "| 경기도|수도권|\n",
      "|   대구|  지방|\n",
      "|   부산|  지방|\n",
      "|   전주|  지방|\n",
      "|   광주|  지방|\n",
      "+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = '''\n",
    "select address,\n",
    "    if (address in ('경기도','서울'), '수도권', '지방') as region\n",
    "from users\n",
    "'''\n",
    "\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7aa2cd7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+\n",
      "|stock_quantity|quantity_level|\n",
      "+--------------+--------------+\n",
      "|            55|     재고 많음|\n",
      "|            40|     재고 중간|\n",
      "|            20|     재고 없음|\n",
      "|            75|     재고 많음|\n",
      "|            35|     재고 중간|\n",
      "+--------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "book_sql1 = '''\n",
    "SELECT stock_quantity,\n",
    "    IF(stock_quantity >= 50, '재고 많음',\n",
    "        IF(stock_quantity >= 30, '재고 중간', '재고 없음')) AS quantity_level\n",
    "FROM books;\n",
    "'''\n",
    "\n",
    "spark.sql(book_sql1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4d9b2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+\n",
      "|stock_quantity|quantity_level|\n",
      "+--------------+--------------+\n",
      "|            55|     재고 많음|\n",
      "|            40|     재고 중간|\n",
      "|            20|     재고 없음|\n",
      "|            75|     재고 많음|\n",
      "|            35|     재고 중간|\n",
      "+--------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "book_sql2 = '''\n",
    "SELECT stock_quantity,\n",
    "    CASE \n",
    "        WHEN stock_quantity >= 50 THEN '재고 많음'\n",
    "        WHEN stock_quantity >= 30 THEN '재고 중간'\n",
    "        ELSE '재고 없음'\n",
    "    END AS quantity_level\n",
    "FROM books;\n",
    "'''\n",
    "\n",
    "spark.sql(book_sql2).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40dd69de",
   "metadata": {},
   "source": [
    "## 실행계획 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8718584e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(1) Project [stock_quantity#6L, if ((stock_quantity#6L >= 50)) 재고 많음 else if ((stock_quantity#6L >= 30)) 재고 중간 else 재고 없음 AS quantity_level#141]\n",
      "+- *(1) Scan ExistingRDD[book_id#0L,title#1,author_fname#2,author_lname#3,pages#4L,released_year#5L,stock_quantity#6L]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(book_sql1).explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ff8fbbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(1) Project [stock_quantity#6L, CASE WHEN (stock_quantity#6L >= 50) THEN 재고 많음 WHEN (stock_quantity#6L >= 30) THEN 재고 중간 ELSE 재고 없음 END AS quantity_level#156]\n",
      "+- *(1) Scan ExistingRDD[book_id#0L,title#1,author_fname#2,author_lname#3,pages#4L,released_year#5L,stock_quantity#6L]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(book_sql2).explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5f9c4a",
   "metadata": {},
   "source": [
    "## GROUP BY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0c5c82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 27:=====================================>                 (69 + 2) / 100]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+\n",
      "|author_lname|count(1)|\n",
      "+------------+--------+\n",
      "|       Jones|       1|\n",
      "|       Davis|       1|\n",
      "|       Smith|       1|\n",
      "|         Doe|       1|\n",
      "|       Brown|       1|\n",
      "+------------+--------+\n",
      "\n",
      "== Physical Plan ==\n",
      "*(2) HashAggregate(keys=[author_lname#3], functions=[count(1)])\n",
      "+- Exchange hashpartitioning(author_lname#3, 200), ENSURE_REQUIREMENTS, [id=#195]\n",
      "   +- *(1) HashAggregate(keys=[author_lname#3], functions=[partial_count(1)])\n",
      "      +- *(1) Project [author_lname#3]\n",
      "         +- *(1) Scan ExistingRDD[book_id#0L,title#1,author_fname#2,author_lname#3,pages#4L,released_year#5L,stock_quantity#6L]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = '''\n",
    "SELECT author_lname, count(*)\n",
    "FROM books\n",
    "GROUP BY author_lname;\n",
    "'''\n",
    "\n",
    "spark.sql(query).show()\n",
    "spark.sql(query).explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d73cde",
   "metadata": {},
   "source": [
    "## 데이터에 열 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fadefa87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------------+------------+-----+-------------+--------------+-----------+\n",
      "|book_id| title|author_fname|author_lname|pages|released_year|stock_quantity|borrowed_by|\n",
      "+-------+------+------------+------------+-----+-------------+--------------+-----------+\n",
      "|      1|Book A|        John|         Doe|  300|         2005|            55|          1|\n",
      "|      2|Book B|        Jane|       Smith|  250|         2010|            40|          2|\n",
      "|      3|Book C|       Emily|       Jones|  180|         2015|            20|          3|\n",
      "|      4|Book D|       Chris|       Brown|  320|         2012|            75|       null|\n",
      "|      5|Book E|        Anna|       Davis|  270|         2008|            35|          6|\n",
      "+-------+------+------------+------------+-----+-------------+--------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "books_data_with_user = [\n",
    "    Row(book_id=1, title=\"Book A\", author_fname=\"John\", author_lname=\"Doe\", pages=300, released_year=2005, stock_quantity=55, borrowed_by=1),\n",
    "    Row(book_id=2, title=\"Book B\", author_fname=\"Jane\", author_lname=\"Smith\", pages=250, released_year=2010, stock_quantity=40, borrowed_by=2),\n",
    "    Row(book_id=3, title=\"Book C\", author_fname=\"Emily\", author_lname=\"Jones\", pages=180, released_year=2015, stock_quantity=20, borrowed_by=3),\n",
    "    Row(book_id=4, title=\"Book D\", author_fname=\"Chris\", author_lname=\"Brown\", pages=320, released_year=2012, stock_quantity=75, borrowed_by=None),\n",
    "    Row(book_id=5, title=\"Book E\", author_fname=\"Anna\", author_lname=\"Davis\", pages=270, released_year=2008, stock_quantity=35, borrowed_by=6)\n",
    "]\n",
    "\n",
    "books_df = books_df.withColumn(\"borrowed_by\", \n",
    "                   F.when(books_df[\"book_id\"] == 1, 1)  \n",
    "                    .when(books_df[\"book_id\"] == 2, 2) \n",
    "                    .when(books_df[\"book_id\"] == 3, 3)\n",
    "                    .when(books_df[\"book_id\"] == 5, 6)\n",
    "                    .otherwise(None) \n",
    ")\n",
    "\n",
    "books_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2f838f",
   "metadata": {},
   "source": [
    "## 데이터 저장\n",
    "- 여러 개의 파티션에 나뉘어 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a5f405eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_df.write.csv('data/output/books.csv', header=True, mode='overwrite' )\n",
    "users_df.write.csv('data/output/users.csv', header=True, mode='overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b69c24c",
   "metadata": {},
   "source": [
    "## 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd82102d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------------+------------+-----+-------------+--------------+-----------+\n",
      "|book_id| title|author_fname|author_lname|pages|released_year|stock_quantity|borrowed_by|\n",
      "+-------+------+------------+------------+-----+-------------+--------------+-----------+\n",
      "|      3|Book C|       Emily|       Jones|  180|         2015|            20|          3|\n",
      "|      4|Book D|       Chris|       Brown|  320|         2012|            75|       null|\n",
      "|      5|Book E|        Anna|       Davis|  270|         2008|            35|          6|\n",
      "|      1|Book A|        John|         Doe|  300|         2005|            55|          1|\n",
      "|      2|Book B|        Jane|       Smith|  250|         2010|            40|          2|\n",
      "+-------+------+------------+------------+-----+-------------+--------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "books_df1 = spark.read.csv('data/output/books.csv', header=True)\n",
    "books_df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd448934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+-------+\n",
      "|user_id|username|address|\n",
      "+-------+--------+-------+\n",
      "|      6|       F|   서울|\n",
      "|      7|       G| 경기도|\n",
      "|      8|       H|   대구|\n",
      "|      9|       I|   부산|\n",
      "|     10|       J|   전주|\n",
      "|     11|       K|   광주|\n",
      "|      1|       A|   서울|\n",
      "|      2|       B|   대전|\n",
      "|      3|       C| 경기도|\n",
      "|      4|       D|   null|\n",
      "|      5|       E|   null|\n",
      "+-------+--------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users_df1 = spark.read.csv('data/output/users.csv', header=True)\n",
    "users_df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "84eb69c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_df1.createOrReplaceTempView('books')\n",
    "users_df1.createOrReplaceTempView('users')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13de0ca",
   "metadata": {},
   "source": [
    "## INNER JOIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8bbcfabd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------------+------------+--------+-------+\n",
      "|book_id| title|author_fname|author_lname|username|address|\n",
      "+-------+------+------------+------------+--------+-------+\n",
      "|      3|Book C|       Emily|       Jones|       C| 경기도|\n",
      "|      5|Book E|        Anna|       Davis|       F|   서울|\n",
      "|      1|Book A|        John|         Doe|       A|   서울|\n",
      "|      2|Book B|        Jane|       Smith|       B|   대전|\n",
      "+-------+------+------------+------------+--------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = '''\n",
    "SELECT book_id, title, author_fname, author_lname, username, address\n",
    "FROM books AS b\n",
    "INNER JOIN users AS u\n",
    "ON b.borrowed_by = u.user_id;\n",
    "'''\n",
    "\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "74ab6b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------------+------------+--------+-------+\n",
      "|book_id| title|author_fname|author_lname|username|address|\n",
      "+-------+------+------------+------------+--------+-------+\n",
      "|      5|Book E|        Anna|       Davis|       F|   서울|\n",
      "|      1|Book A|        John|         Doe|       A|   서울|\n",
      "+-------+------+------------+------------+--------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = '''\n",
    "SELECT book_id, title, author_fname, author_lname, username, address\n",
    "FROM books AS b\n",
    "INNER JOIN users AS u\n",
    "ON b.borrowed_by = u.user_id\n",
    "WHERE address == '서울';\n",
    "'''\n",
    "\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054941ae",
   "metadata": {},
   "source": [
    "## LEFT JOIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "09414d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------------+------------+--------+-------+\n",
      "|book_id| title|author_fname|author_lname|username|address|\n",
      "+-------+------+------------+------------+--------+-------+\n",
      "|      3|Book C|       Emily|       Jones|       C| 경기도|\n",
      "|      4|Book D|       Chris|       Brown|    null|   null|\n",
      "|      5|Book E|        Anna|       Davis|       F|   서울|\n",
      "|      1|Book A|        John|         Doe|       A|   서울|\n",
      "|      2|Book B|        Jane|       Smith|       B|   대전|\n",
      "+-------+------+------------+------------+--------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = '''\n",
    "SELECT book_id, title, author_fname, author_lname, username, address\n",
    "FROM books AS b\n",
    "LEFT JOIN users AS u\n",
    "ON b.borrowed_by = u.user_id;\n",
    "'''\n",
    "\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7e1dc549",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 62:===================================================>   (94 + 2) / 100]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+--------------------+\n",
      "|user_id|username|borrowed_books_count|\n",
      "+-------+--------+--------------------+\n",
      "|     11|       K|                   0|\n",
      "|      1|       A|                   1|\n",
      "|      5|       E|                   0|\n",
      "|      2|       B|                   1|\n",
      "|      7|       G|                   0|\n",
      "|      3|       C|                   1|\n",
      "|      6|       F|                   1|\n",
      "|      4|       D|                   0|\n",
      "|      9|       I|                   0|\n",
      "|      8|       H|                   0|\n",
      "|     10|       J|                   0|\n",
      "+-------+--------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 사용자 별로 대여한 책 수\n",
    "query = '''\n",
    "SELECT \n",
    "    u.user_id, \n",
    "    u.username, \n",
    "    COUNT(b.book_id) AS borrowed_books_count\n",
    "FROM users AS u\n",
    "LEFT JOIN books AS b\n",
    "ON b.borrowed_by = u.user_id\n",
    "GROUP BY user_id, username;\n",
    "'''\n",
    "\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a785f29",
   "metadata": {},
   "source": [
    "## RIGHT JOIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fe34e270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------------+------------+--------+-------+\n",
      "|book_id| title|author_fname|author_lname|username|address|\n",
      "+-------+------+------------+------------+--------+-------+\n",
      "|      5|Book E|        Anna|       Davis|       F|   서울|\n",
      "|   null|  null|        null|        null|       G| 경기도|\n",
      "|   null|  null|        null|        null|       H|   대구|\n",
      "|   null|  null|        null|        null|       I|   부산|\n",
      "|   null|  null|        null|        null|       J|   전주|\n",
      "|   null|  null|        null|        null|       K|   광주|\n",
      "|      1|Book A|        John|         Doe|       A|   서울|\n",
      "|      2|Book B|        Jane|       Smith|       B|   대전|\n",
      "|      3|Book C|       Emily|       Jones|       C| 경기도|\n",
      "|   null|  null|        null|        null|       D|   null|\n",
      "|   null|  null|        null|        null|       E|   null|\n",
      "+-------+------+------------+------------+--------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = '''\n",
    "SELECT book_id, title, author_fname, author_lname, username, address\n",
    "FROM books AS b\n",
    "RIGHT JOIN users AS u\n",
    "ON b.borrowed_by = u.user_id;\n",
    "'''\n",
    "\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7538592c",
   "metadata": {},
   "source": [
    "## CASE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f9ca8110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-----+-----------+\n",
      "|book_id| title|pages|book_length|\n",
      "+-------+------+-----+-----------+\n",
      "|      3|Book C|  180|      short|\n",
      "|      4|Book D|  320|       long|\n",
      "|      5|Book E|  270|      short|\n",
      "|      1|Book A|  300|       long|\n",
      "|      2|Book B|  250|      short|\n",
      "+-------+------+-----+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pages >= 300 이면 long, else short\n",
    "\n",
    "query = '''\n",
    "SELECT \n",
    "    book_id,\n",
    "    title,\n",
    "    pages,\n",
    "    CASE \n",
    "        WHEN pages >= 300 THEN 'long'\n",
    "        ELSE 'short'\n",
    "    END AS book_length\n",
    "FROM books\n",
    "'''\n",
    "\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0edcec7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+--------------+--------------------+\n",
      "|book_id| title|stock_quantity|stock_quantity_level|\n",
      "+-------+------+--------------+--------------------+\n",
      "|      3|Book C|            20|                부족|\n",
      "|      4|Book D|            75|                충분|\n",
      "|      5|Book E|            35|                보통|\n",
      "|      1|Book A|            55|                충분|\n",
      "|      2|Book B|            40|                보통|\n",
      "+-------+------+--------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# stock_quantity >= 50 이면 충분, >= 30 이면 보통, 부족\n",
    "\n",
    "query = '''\n",
    "SELECT \n",
    "    book_id,\n",
    "    title,\n",
    "    stock_quantity,\n",
    "    CASE \n",
    "        WHEN stock_quantity >= 50 THEN '충분'\n",
    "        WHEN stock_quantity >= 30 THEN '보통'\n",
    "        ELSE '부족'\n",
    "    END AS stock_quantity_level\n",
    "FROM books\n",
    "'''\n",
    "\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de4372c",
   "metadata": {},
   "source": [
    "## LIMIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "000655dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 70:=================================>                    (124 + 2) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+------------+\n",
      "|author_fname|author_lname|borrow_count|\n",
      "+------------+------------+------------+\n",
      "|        Anna|       Davis|           1|\n",
      "+------------+------------+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 70:============================================>         (166 + 3) / 200]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# 대여가 가장 많이 된 책의 작가 조회\n",
    "query = '''\n",
    "SELECT author_fname, author_lname, count(book_id) as borrow_count\n",
    "FROM books\n",
    "GROUP BY author_fname, author_lname\n",
    "ORDER BY borrow_count DESC\n",
    "LIMIT 1\n",
    "'''\n",
    "\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b72338c",
   "metadata": {},
   "source": [
    "## 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "05758d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------+\n",
      "|released_year|borrow_count|\n",
      "+-------------+------------+\n",
      "|         2005|           1|\n",
      "|         2008|           1|\n",
      "|         2015|           1|\n",
      "|         2010|           1|\n",
      "+-------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 책의 발행 연도별 대여 현황\n",
    "query = '''\n",
    "SELECT released_year, COUNT(borrowed_by) AS borrow_count\n",
    "FROM books AS b\n",
    "INNER JOIN users AS u\n",
    "ON b.borrowed_by = u.user_id\n",
    "GROUP BY released_year\n",
    "'''\n",
    "\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c939215b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+\n",
      "|address|borrow_count|\n",
      "+-------+------------+\n",
      "|   대전|           1|\n",
      "| 경기도|           1|\n",
      "|   서울|           2|\n",
      "+-------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 사용자 지역별 대여된 책 수\n",
    "query = '''\n",
    "SELECT address, COUNT(borrowed_by) AS borrow_count\n",
    "FROM books AS b\n",
    "INNER JOIN users AS u\n",
    "ON b.borrowed_by = u.user_id\n",
    "GROUP BY address\n",
    "'''\n",
    "\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5b64ff0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+\n",
      "| title|borrow_status|\n",
      "+------+-------------+\n",
      "|Book C|     Borrowed|\n",
      "+------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 재고가 부족한 책과 대여 상태\n",
    "# 재고가 30개 미만인 책과 해당 책이 대여된 상태인지 확인\n",
    "query = '''\n",
    "SELECT title, CASE WHEN borrowed_by IS NULL THEN 'Not Borrowed'\n",
    "                    ELSE 'Borrowed' END AS borrow_status\n",
    "FROM books\n",
    "WHERE stock_quantity < 30 \n",
    "'''\n",
    "\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c61fe447",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (spark_start)",
   "language": "python",
   "name": "spark_start"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
