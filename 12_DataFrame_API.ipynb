{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0b4e9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/06 16:21:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"FirstSparkSessionApp\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f035f612",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.format('csv').load('data/2015-summary.csv', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61269777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(DEST_COUNTRY_NAME,StringType,true),StructField(ORIGIN_COUNTRY_NAME,StringType,true),StructField(count,IntegerType,true)))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11d6bee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DEST_COUNTRY_NAME: string (nullable = true)\n",
      " |-- ORIGIN_COUNTRY_NAME: string (nullable = true)\n",
      " |-- count: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdcdf714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Romania', count=15)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83d4bcd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+--------------------+-------------------+-----+\n",
      "|       United States|            Romania|   15|\n",
      "|       United States|            Croatia|    1|\n",
      "|       United States|            Ireland|  344|\n",
      "|               Egypt|      United States|   15|\n",
      "|       United States|              India|   62|\n",
      "|       United States|          Singapore|    1|\n",
      "|       United States|            Grenada|   62|\n",
      "|          Costa Rica|      United States|  588|\n",
      "|             Senegal|      United States|   40|\n",
      "|             Moldova|      United States|    1|\n",
      "|       United States|       Sint Maarten|  325|\n",
      "|       United States|   Marshall Islands|   39|\n",
      "|              Guyana|      United States|   64|\n",
      "|               Malta|      United States|    1|\n",
      "|            Anguilla|      United States|   41|\n",
      "|             Bolivia|      United States|   30|\n",
      "|       United States|           Paraguay|    6|\n",
      "|             Algeria|      United States|    4|\n",
      "|Turks and Caicos ...|      United States|  230|\n",
      "|       United States|          Gibraltar|    1|\n",
      "+--------------------+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27eb18cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|DEST_COUNTRY_NAME|\n",
      "+-----------------+\n",
      "|    United States|\n",
      "|    United States|\n",
      "|    United States|\n",
      "|            Egypt|\n",
      "|    United States|\n",
      "+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"DEST_COUNTRY_NAME\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afb032e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadd0b8d",
   "metadata": {},
   "source": [
    "### dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "621b719c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|DEST_COUNTRY_NAME|\n",
      "+-----------------+\n",
      "|         Anguilla|\n",
      "|           Russia|\n",
      "|         Paraguay|\n",
      "|          Senegal|\n",
      "|           Sweden|\n",
      "+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_dup = df.select('DEST_COUNTRY_NAME').dropDuplicates()\n",
    "df_dup.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1983b5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|DEST_COUNTRY_NAME|\n",
      "+-----------------+\n",
      "|         Anguilla|\n",
      "|           Russia|\n",
      "|         Paraguay|\n",
      "|          Senegal|\n",
      "|           Sweden|\n",
      "+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_dup = df.select('DEST_COUNTRY_NAME').dropDuplicates().cache()\n",
    "df_dup.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "468f7226",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dup.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77ade70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+--------------------+-------------------+-----+\n",
      "|             Algeria|      United States|    4|\n",
      "|              Angola|      United States|   15|\n",
      "|            Anguilla|      United States|   41|\n",
      "| Antigua and Barbuda|      United States|  126|\n",
      "|           Argentina|      United States|  180|\n",
      "|               Aruba|      United States|  346|\n",
      "|           Australia|      United States|  329|\n",
      "|             Austria|      United States|   62|\n",
      "|          Azerbaijan|      United States|   21|\n",
      "|             Bahrain|      United States|   19|\n",
      "|            Barbados|      United States|  154|\n",
      "|             Belgium|      United States|  259|\n",
      "|              Belize|      United States|  188|\n",
      "|             Bermuda|      United States|  183|\n",
      "|             Bolivia|      United States|   30|\n",
      "|Bonaire, Sint Eus...|      United States|   58|\n",
      "|              Brazil|      United States|  853|\n",
      "|British Virgin Is...|      United States|  107|\n",
      "|            Bulgaria|      United States|    3|\n",
      "|        Burkina Faso|      United States|    1|\n",
      "+--------------------+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sort('DEST_COUNTRY_NAME').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1637385",
   "metadata": {},
   "source": [
    "### expr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f7bf4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "\n",
    "df2 = df.withColumn('withInCountry', expr('ORIGIN_COUNTRY_NAME==DEST_COUNTRY_NAME'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa843bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+-------------+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|withInCountry|\n",
      "+--------------------+-------------------+-----+-------------+\n",
      "|       United States|            Romania|   15|        false|\n",
      "|       United States|            Croatia|    1|        false|\n",
      "|       United States|            Ireland|  344|        false|\n",
      "|               Egypt|      United States|   15|        false|\n",
      "|       United States|              India|   62|        false|\n",
      "|       United States|          Singapore|    1|        false|\n",
      "|       United States|            Grenada|   62|        false|\n",
      "|          Costa Rica|      United States|  588|        false|\n",
      "|             Senegal|      United States|   40|        false|\n",
      "|             Moldova|      United States|    1|        false|\n",
      "|       United States|       Sint Maarten|  325|        false|\n",
      "|       United States|   Marshall Islands|   39|        false|\n",
      "|              Guyana|      United States|   64|        false|\n",
      "|               Malta|      United States|    1|        false|\n",
      "|            Anguilla|      United States|   41|        false|\n",
      "|             Bolivia|      United States|   30|        false|\n",
      "|       United States|           Paraguay|    6|        false|\n",
      "|             Algeria|      United States|    4|        false|\n",
      "|Turks and Caicos ...|      United States|  230|        false|\n",
      "|       United States|          Gibraltar|    1|        false|\n",
      "+--------------------+-------------------+-----+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db4798b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df.withColumn('category', expr('ORIGIN_COUNTRY_NAME==DEST_COUNTRY_NAME'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ffaf287a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+--------+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|category|\n",
      "+--------------------+-------------------+-----+--------+\n",
      "|       United States|            Romania|   15|   false|\n",
      "|       United States|            Croatia|    1|   false|\n",
      "|       United States|            Ireland|  344|   false|\n",
      "|               Egypt|      United States|   15|   false|\n",
      "|       United States|              India|   62|   false|\n",
      "|       United States|          Singapore|    1|   false|\n",
      "|       United States|            Grenada|   62|   false|\n",
      "|          Costa Rica|      United States|  588|   false|\n",
      "|             Senegal|      United States|   40|   false|\n",
      "|             Moldova|      United States|    1|   false|\n",
      "|       United States|       Sint Maarten|  325|   false|\n",
      "|       United States|   Marshall Islands|   39|   false|\n",
      "|              Guyana|      United States|   64|   false|\n",
      "|               Malta|      United States|    1|   false|\n",
      "|            Anguilla|      United States|   41|   false|\n",
      "|             Bolivia|      United States|   30|   false|\n",
      "|       United States|           Paraguay|    6|   false|\n",
      "|             Algeria|      United States|    4|   false|\n",
      "|Turks and Caicos ...|      United States|  230|   false|\n",
      "|       United States|          Gibraltar|    1|   false|\n",
      "+--------------------+-------------------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c43dfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df.withColumn('category', expr('CASE WHEN count < 10 THEN \"under\" WHEN count >=10 THEN \"upper\" END'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5fba6057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|withInCountry|count|\n",
      "+-------------+-----+\n",
      "|         true|    1|\n",
      "|        false|  255|\n",
      "+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.groupBy('withInCountry').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "15f82a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|category|count|\n",
      "+--------+-----+\n",
      "|    true|    1|\n",
      "|   false|  255|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.groupBy('category').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc19083b",
   "metadata": {},
   "source": [
    "### spark.sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c5c41bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('mobility_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6681f55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Romania|   15|\n",
      "|    United States|            Croatia|    1|\n",
      "|    United States|            Ireland|  344|\n",
      "|            Egypt|      United States|   15|\n",
      "|    United States|              India|   62|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from mobility_data\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "56fc99be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+--------------------+-------------------+-----+\n",
      "|       United States|            Croatia|    1|\n",
      "|       United States|          Singapore|    1|\n",
      "|             Moldova|      United States|    1|\n",
      "|               Malta|      United States|    1|\n",
      "|             Algeria|      United States|    4|\n",
      "|       United States|          Gibraltar|    1|\n",
      "|Saint Vincent and...|      United States|    1|\n",
      "|            Suriname|      United States|    1|\n",
      "|       United States|             Cyprus|    1|\n",
      "|       United States|           Malaysia|    3|\n",
      "|            Thailand|      United States|    3|\n",
      "|             Liberia|      United States|    2|\n",
      "|             Hungary|      United States|    2|\n",
      "|       United States|            Vietnam|    2|\n",
      "|        Burkina Faso|      United States|    1|\n",
      "|            Djibouti|      United States|    1|\n",
      "|       United States|            Estonia|    1|\n",
      "|       United States|            Hungary|    3|\n",
      "|              Zambia|      United States|    1|\n",
      "|            Malaysia|      United States|    2|\n",
      "+--------------------+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Projection, filter\n",
    "df5 = df.where('count<5')\n",
    "df5.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "31b2f57b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b0b451e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Croatia|    1|\n",
      "|    United States|          Singapore|    1|\n",
      "|    United States|          Gibraltar|    1|\n",
      "|    United States|             Cyprus|    1|\n",
      "|    United States|           Malaysia|    3|\n",
      "|    United States|            Vietnam|    2|\n",
      "|    United States|            Estonia|    1|\n",
      "|    United States|            Hungary|    3|\n",
      "|    United States|           Thailand|    4|\n",
      "|    United States|            Liberia|    2|\n",
      "|    United States|              Malta|    2|\n",
      "|    United States|          Lithuania|    1|\n",
      "|    United States|           Bulgaria|    1|\n",
      "|    United States|            Georgia|    1|\n",
      "|    United States|            Bahrain|    1|\n",
      "|    United States|   Papua New Guinea|    1|\n",
      "|    United States|          Greenland|    4|\n",
      "|    United States|          Indonesia|    2|\n",
      "|    United States|         Montenegro|    1|\n",
      "|    United States|            Namibia|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df7 = df.where(\"count < 5\").where(\"ORIGIN_COUNTRY_NAME <> 'United States'\")\n",
    "df7.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ca688f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/09 10:38:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"SecondSparkSessionApp\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8bebe6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.format('csv').option('header', 'true')\\\n",
    "            .option('inferSchema','true')\\\n",
    "            .load('data/emp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e42585cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- empno: integer (nullable = true)\n",
      " |-- ename: string (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- mgr: integer (nullable = true)\n",
      " |-- hiredate: string (nullable = true)\n",
      " |-- sal: integer (nullable = true)\n",
      " |-- comm: integer (nullable = true)\n",
      " |-- deptno: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe63d40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---------+----+----------+----+----+------+\n",
      "|empno| ename|      job| mgr|  hiredate| sal|comm|deptno|\n",
      "+-----+------+---------+----+----------+----+----+------+\n",
      "| 7369| SMITH|    CLERK|7902|1980-12-17| 800|null|    20|\n",
      "| 7499| ALLEN| SALESMAN|7698|1981-02-20|1600| 300|    30|\n",
      "| 7521|  WARD| SALESMAN|7698|1981-02-22|1250| 500|    30|\n",
      "| 7566| JONES|  MANAGER|7839|1981-04-02|2975|null|    20|\n",
      "| 7654|MARTIN| SALESMAN|7698|1981-09-28|1250|1400|    30|\n",
      "| 7698| BLAKE|  MANAGER|7839|1981-05-01|2850|null|    30|\n",
      "| 7782| CLARK|  MANAGER|7839|1981-06-09|2450|null|    10|\n",
      "| 7788| SCOTT|  ANALYST|7566|1987-04-19|3000|null|    20|\n",
      "| 7839|  KING|PRESIDENT|null|1981-11-17|5000|null|    10|\n",
      "| 7844|TURNER| SALESMAN|7698|1981-09-08|1500|   0|    30|\n",
      "| 7876| ADAMS|    CLERK|7788|1987-05-23|1100|null|    20|\n",
      "| 7900| JAMES|    CLERK|7698|1981-12-03| 950|null|    30|\n",
      "| 7902|  FORD|  ANALYST|7566|1981-12-03|3000|null|    20|\n",
      "| 7934|MILLER|    CLERK|7782|1982-01-23|1300|null|    10|\n",
      "| 9292|  JACK|    CLERK|7782|1982-01-23|3200|null|    70|\n",
      "+-----+------+---------+----+----------+----+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "629a6fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+\n",
      "| ename|deptno|\n",
      "+------+------+\n",
      "| SMITH|    20|\n",
      "| ALLEN|    30|\n",
      "|  WARD|    30|\n",
      "| JONES|    20|\n",
      "|MARTIN|    30|\n",
      "| BLAKE|    30|\n",
      "| CLARK|    10|\n",
      "| SCOTT|    20|\n",
      "|  KING|    10|\n",
      "|TURNER|    30|\n",
      "| ADAMS|    20|\n",
      "| JAMES|    30|\n",
      "|  FORD|    20|\n",
      "|MILLER|    10|\n",
      "|  JACK|    70|\n",
      "+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('ename', 'deptno').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ab39a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|ename|deptno|\n",
      "+-----+------+\n",
      "|SMITH|    20|\n",
      "|JONES|    20|\n",
      "|SCOTT|    20|\n",
      "|ADAMS|    20|\n",
      "| FORD|    20|\n",
      "+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('ename','deptno').where('deptno=20').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c11eaf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|count(job)|\n",
      "+----------+\n",
      "|        15|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import count\n",
    "\n",
    "df.select(count('job')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7d321bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|      15|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# null 포함해서 카운트\n",
    "df.selectExpr('count(*)').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a45f5fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 16:=================================================>     (90 + 2) / 100]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|      job|\n",
      "+---------+\n",
      "|  ANALYST|\n",
      "| SALESMAN|\n",
      "|    CLERK|\n",
      "|  MANAGER|\n",
      "|PRESIDENT|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('job').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9c789db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('job').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60e5280b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 26:=============================>                        (111 + 2) / 200]\r",
      "\r",
      "[Stage 26:==========================================>           (156 + 2) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|count(DISTINCT job)|\n",
      "+-------------------+\n",
      "|                  5|\n",
      "+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 26:=====================================================>(198 + 2) / 200]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import countDistinct,approx_count_distinct\n",
    "\n",
    "df.select(countDistinct('job')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d498c240",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+\n",
      "|approx_count_distinct(job)|\n",
      "+--------------------------+\n",
      "|                         5|\n",
      "+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(approx_count_distinct('job',0.1)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ac38cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+\n",
      "|first(ename)|last(ename)|\n",
      "+------------+-----------+\n",
      "|       SMITH|       JACK|\n",
      "+------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "df.select(first('ename'), last('ename')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ebef9607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+----------+----------+\n",
      "|count(empno)|count(1)|max(ename)|min(ename)|\n",
      "+------------+--------+----------+----------+\n",
      "|          15|      15|      WARD|     ADAMS|\n",
      "+------------+--------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(count('empno'),count('*'),max('ename'),min('ename')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3010e213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|sum(sal)|\n",
      "+--------+\n",
      "|   32225|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(sum('sal')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7c43f716",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 37:===============================>                      (118 + 2) / 200]\r",
      "\r",
      "[Stage 37:=============================================>        (168 + 2) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|sum(DISTINCT sal)|\n",
      "+-----------------+\n",
      "|            27975|\n",
      "+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.selectExpr('sum(distinct(sal))').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "77bf41e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 40:================================>                     (122 + 2) / 200]\r",
      "\r",
      "[Stage 40:==============================================>       (171 + 2) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|avg(DISTINCT sal)|\n",
      "+-----------------+\n",
      "|2151.923076923077|\n",
      "+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.selectExpr('avg(distinct(sal))').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e42420c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+------------------+------------------+\n",
      "|total_count|total_salary|        avg_salary|       mean_salary|\n",
      "+-----------+------------+------------------+------------------+\n",
      "|         15|       32225|2148.3333333333335|2148.3333333333335|\n",
      "+-----------+------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(count('sal').alias('total_count'),\n",
    "         sum('sal').alias('total_salary'),\n",
    "         avg('sal').alias('avg_salary'),\n",
    "         expr('mean(sal)').alias('mean_salary')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6205230",
   "metadata": {},
   "source": [
    "## groupBy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "573ddbc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[empno: int, ename: string, job: string, mgr: int, hiredate: string, sal: int, comm: int, deptno: int]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b370d71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|      job|count|\n",
      "+---------+-----+\n",
      "|  ANALYST|    2|\n",
      "| SALESMAN|    4|\n",
      "|    CLERK|    5|\n",
      "|  MANAGER|    3|\n",
      "|PRESIDENT|    1|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('job').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80f691d",
   "metadata": {},
   "source": [
    "## agg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "31b1e093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+\n",
      "|      job|           SAL_AVG|\n",
      "+---------+------------------+\n",
      "|  ANALYST|            3000.0|\n",
      "| SALESMAN|            1400.0|\n",
      "|    CLERK|            1470.0|\n",
      "|  MANAGER|2758.3333333333335|\n",
      "|PRESIDENT|            5000.0|\n",
      "+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('job').agg(expr('avg(sal) as SAL_AVG')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d40bee0",
   "metadata": {},
   "source": [
    "### 모집단 전체 표준편차"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a25bf85c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+\n",
      "|      job|           SAL_AVG|\n",
      "+---------+------------------+\n",
      "|  ANALYST|               0.0|\n",
      "| SALESMAN|154.11035007422439|\n",
      "|    CLERK| 880.6815542521599|\n",
      "|  MANAGER|223.91714737574006|\n",
      "|PRESIDENT|               0.0|\n",
      "+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('job').agg(expr('stddev_pop(sal) as SAL_AVG')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7bc637",
   "metadata": {},
   "source": [
    "### 표본 표준편차"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dc7cfb4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+\n",
      "|      job|           SAL_AVG|\n",
      "+---------+------------------+\n",
      "|  ANALYST|               0.0|\n",
      "| SALESMAN|177.95130420052183|\n",
      "|    CLERK| 984.6319109189992|\n",
      "|  MANAGER|274.24137786507225|\n",
      "|PRESIDENT|              null|\n",
      "+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('job').agg(expr('std(sal) as SAL_AVG')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8296ea0b",
   "metadata": {},
   "source": [
    "## 윈도우 함수\n",
    "1. 순위, 정렬 : rank(), row_number(), dense_rank()\n",
    "2. 누계 : sum(), avg(), max(), min() + over()\n",
    "3. 이동평균 : over + rowsBetween, rangeBetween\n",
    "4. 시차, 선형 : lag, lead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9fce211b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'RANK() OVER (ORDER BY sal DESC NULLS LAST unspecifiedframe$())'>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "windowspec = Window.orderBy(desc('sal'))\n",
    "salAllRank = rank().over(windowspec)\n",
    "salAllRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "be2da1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/09 13:39:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---------+----+----------+----+----+------+-----------+\n",
      "|empno| ename|      job| mgr|  hiredate| sal|comm|deptno|salary_rank|\n",
      "+-----+------+---------+----+----------+----+----+------+-----------+\n",
      "| 7839|  KING|PRESIDENT|null|1981-11-17|5000|null|    10|          1|\n",
      "| 9292|  JACK|    CLERK|7782|1982-01-23|3200|null|    70|          2|\n",
      "| 7788| SCOTT|  ANALYST|7566|1987-04-19|3000|null|    20|          3|\n",
      "| 7902|  FORD|  ANALYST|7566|1981-12-03|3000|null|    20|          3|\n",
      "| 7566| JONES|  MANAGER|7839|1981-04-02|2975|null|    20|          5|\n",
      "| 7698| BLAKE|  MANAGER|7839|1981-05-01|2850|null|    30|          6|\n",
      "| 7782| CLARK|  MANAGER|7839|1981-06-09|2450|null|    10|          7|\n",
      "| 7499| ALLEN| SALESMAN|7698|1981-02-20|1600| 300|    30|          8|\n",
      "| 7844|TURNER| SALESMAN|7698|1981-09-08|1500|   0|    30|          9|\n",
      "| 7934|MILLER|    CLERK|7782|1982-01-23|1300|null|    10|         10|\n",
      "| 7521|  WARD| SALESMAN|7698|1981-02-22|1250| 500|    30|         11|\n",
      "| 7654|MARTIN| SALESMAN|7698|1981-09-28|1250|1400|    30|         11|\n",
      "| 7876| ADAMS|    CLERK|7788|1987-05-23|1100|null|    20|         13|\n",
      "| 7900| JAMES|    CLERK|7698|1981-12-03| 950|null|    30|         14|\n",
      "| 7369| SMITH|    CLERK|7902|1980-12-17| 800|null|    20|         15|\n",
      "+-----+------+---------+----+----------+----+----+------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn('salary_rank', salAllRank).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "24cf25da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+\n",
      "|empno|salary_rank|\n",
      "+-----+-----------+\n",
      "| 7839|          1|\n",
      "| 9292|          2|\n",
      "| 7788|          3|\n",
      "| 7902|          3|\n",
      "| 7566|          5|\n",
      "| 7698|          6|\n",
      "| 7782|          7|\n",
      "| 7499|          8|\n",
      "| 7844|          9|\n",
      "| 7934|         10|\n",
      "| 7521|         11|\n",
      "| 7654|         11|\n",
      "| 7876|         13|\n",
      "| 7900|         14|\n",
      "| 7369|         15|\n",
      "+-----+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/09 13:45:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    }
   ],
   "source": [
    "df.select('empno', salAllRank.alias('salary_rank')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3ac1ed02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.window.WindowSpec at 0x7f9f97ee9c70>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "windowspec = Window.partitionBy('job').orderBy(desc('sal'))\n",
    "windowspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "baeacad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 107:==================================================>   (94 + 2) / 100]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+----+----------+\n",
      "|      job| ename| sal|salJobRank|\n",
      "+---------+------+----+----------+\n",
      "|  ANALYST| SCOTT|3000|         1|\n",
      "|  ANALYST|  FORD|3000|         1|\n",
      "| SALESMAN| ALLEN|1600|         1|\n",
      "| SALESMAN|TURNER|1500|         2|\n",
      "| SALESMAN|  WARD|1250|         3|\n",
      "| SALESMAN|MARTIN|1250|         3|\n",
      "|    CLERK|  JACK|3200|         1|\n",
      "|    CLERK|MILLER|1300|         2|\n",
      "|    CLERK| ADAMS|1100|         3|\n",
      "|    CLERK| JAMES| 950|         4|\n",
      "|    CLERK| SMITH| 800|         5|\n",
      "|  MANAGER| JONES|2975|         1|\n",
      "|  MANAGER| BLAKE|2850|         2|\n",
      "|  MANAGER| CLARK|2450|         3|\n",
      "|PRESIDENT|  KING|5000|         1|\n",
      "+---------+------+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('job', 'ename', 'sal', rank().over(windowspec).alias('salJobRank')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2de94bc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[empno: int, ename: string, job: string, mgr: int, hiredate: string, sal: int, comm: int, deptno: int]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d8e62a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+-----------+\n",
      "|deptno| sal|deptSalRank|\n",
      "+------+----+-----------+\n",
      "|    20|3000|          1|\n",
      "|    20|3000|          1|\n",
      "|    20|2975|          3|\n",
      "|    20|1100|          4|\n",
      "|    20| 800|          5|\n",
      "|    10|5000|          1|\n",
      "|    10|2450|          2|\n",
      "|    10|1300|          3|\n",
      "|    70|3200|          1|\n",
      "|    30|2850|          1|\n",
      "|    30|1600|          2|\n",
      "|    30|1500|          3|\n",
      "|    30|1250|          4|\n",
      "|    30|1250|          4|\n",
      "|    30| 950|          6|\n",
      "+------+----+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "windowspec = Window.partitionBy('deptno').orderBy(desc('sal'))\n",
    "df.select('deptno', 'sal', rank().over(windowspec).alias('deptSalRank')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1cae85f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+----+----------------+\n",
      "| ename|deptno| sal|dept_salary_rank|\n",
      "+------+------+----+----------------+\n",
      "| SCOTT|    20|3000|               1|\n",
      "|  FORD|    20|3000|               2|\n",
      "| JONES|    20|2975|               3|\n",
      "| ADAMS|    20|1100|               4|\n",
      "| SMITH|    20| 800|               5|\n",
      "|  KING|    10|5000|               1|\n",
      "| CLARK|    10|2450|               2|\n",
      "|MILLER|    10|1300|               3|\n",
      "|  JACK|    70|3200|               1|\n",
      "| BLAKE|    30|2850|               1|\n",
      "| ALLEN|    30|1600|               2|\n",
      "|TURNER|    30|1500|               3|\n",
      "|  WARD|    30|1250|               4|\n",
      "|MARTIN|    30|1250|               5|\n",
      "| JAMES|    30| 950|               6|\n",
      "+------+------+----+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1 = df.withColumn('dept_salary_rank',row_number().over(windowspec))\n",
    "df1.select('ename','deptno','sal','dept_salary_rank').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c1328a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+----+----------+\n",
      "| ename|deptno| sal|cum_salary|\n",
      "+------+------+----+----------+\n",
      "| SMITH|    20| 800|       800|\n",
      "| JONES|    20|2975|      3775|\n",
      "| SCOTT|    20|3000|      6775|\n",
      "| ADAMS|    20|1100|      7875|\n",
      "|  FORD|    20|3000|     10875|\n",
      "| CLARK|    10|2450|      2450|\n",
      "|  KING|    10|5000|      7450|\n",
      "|MILLER|    10|1300|      8750|\n",
      "|  JACK|    70|3200|      3200|\n",
      "| ALLEN|    30|1600|      1600|\n",
      "|  WARD|    30|1250|      2850|\n",
      "|MARTIN|    30|1250|      4100|\n",
      "| BLAKE|    30|2850|      6950|\n",
      "|TURNER|    30|1500|      8450|\n",
      "| JAMES|    30| 950|      9400|\n",
      "+------+------+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 부서별 급여 누적 합계\n",
    "windowspec = Window.partitionBy('deptno').orderBy('empno')\n",
    "df2 = df.withColumn('cum_salary', sum('sal').over(windowspec))\n",
    "df2.select('ename','deptno','sal','cum_salary').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2c58844e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 147:=====================================================>(99 + 1) / 100]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+------------------+\n",
      "|deptno| sal|      dept_avg_sal|\n",
      "+------+----+------------------+\n",
      "|    20| 800|            2175.0|\n",
      "|    20|2975|            2175.0|\n",
      "|    20|3000|            2175.0|\n",
      "|    20|1100|            2175.0|\n",
      "|    20|3000|            2175.0|\n",
      "|    10|2450|2916.6666666666665|\n",
      "|    10|5000|2916.6666666666665|\n",
      "|    10|1300|2916.6666666666665|\n",
      "|    70|3200|            3200.0|\n",
      "|    30|1600|1566.6666666666667|\n",
      "|    30|1250|1566.6666666666667|\n",
      "|    30|1250|1566.6666666666667|\n",
      "|    30|2850|1566.6666666666667|\n",
      "|    30|1500|1566.6666666666667|\n",
      "|    30| 950|1566.6666666666667|\n",
      "+------+----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 부서별 평균 급여\n",
    "windowspec = Window.partitionBy('deptno')\n",
    "df3 = df.withColumn('dept_avg_sal', avg('sal').over(windowspec))\n",
    "df3.select('deptno','sal','dept_avg_sal').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ef042b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+\n",
      "|deptno|      dept_avg_sal|\n",
      "+------+------------------+\n",
      "|    20|            2175.0|\n",
      "|    10|2916.6666666666665|\n",
      "|    70|            3200.0|\n",
      "|    30|1566.6666666666667|\n",
      "+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('deptno').agg(avg('sal').alias('dept_avg_sal')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dda1980a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+-----------+-----------+\n",
      "|deptno| sal|prev_salary|next_salary|\n",
      "+------+----+-----------+-----------+\n",
      "|    20| 800|       null|       2975|\n",
      "|    20|2975|        800|       3000|\n",
      "|    20|3000|       2975|       1100|\n",
      "|    20|1100|       3000|       3000|\n",
      "|    20|3000|       1100|       null|\n",
      "|    10|2450|       null|       5000|\n",
      "|    10|5000|       2450|       1300|\n",
      "|    10|1300|       5000|       null|\n",
      "|    70|3200|       null|       null|\n",
      "|    30|1600|       null|       1250|\n",
      "|    30|1250|       1600|       1250|\n",
      "|    30|1250|       1250|       2850|\n",
      "|    30|2850|       1250|       1500|\n",
      "|    30|1500|       2850|        950|\n",
      "|    30| 950|       1500|       null|\n",
      "+------+----+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lag: 현재 행 기준으로 이전 행의 값을 가져옴\n",
    "# lead: 현재 행 기준으로 다음 행의 값을 가져옴\n",
    "\n",
    "windowspec = Window.partitionBy('deptno').orderBy('empno')\n",
    "df4 = df.withColumn('prev_salary', lag('sal').over(windowspec))\\\n",
    "        .withColumn('next_salary', lead('sal').over(windowspec))\n",
    "df4.select('deptno','sal','prev_salary','next_salary').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a44b096c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+--------+--------+\n",
      "|deptno|      job|count(1)|sum(sal)|\n",
      "+------+---------+--------+--------+\n",
      "|    20|  ANALYST|       2|    6000|\n",
      "|    20|  MANAGER|       1|    2975|\n",
      "|    30|  MANAGER|       1|    2850|\n",
      "|    70|    CLERK|       1|    3200|\n",
      "|    30| SALESMAN|       4|    5600|\n",
      "|    30|    CLERK|       1|     950|\n",
      "|    20|    CLERK|       2|    1900|\n",
      "|    10|PRESIDENT|       1|    5000|\n",
      "|    10|    CLERK|       1|    1300|\n",
      "|    10|  MANAGER|       1|    2450|\n",
      "+------+---------+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('deptno','job').agg(count('*'),sum('sal')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "057d9776",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 211:=============================>                       (110 + 2) / 200]\r",
      "\r",
      "[Stage 211:=============================================>       (171 + 2) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+--------+--------+\n",
      "|deptno|      job|count(1)|sum(sal)|\n",
      "+------+---------+--------+--------+\n",
      "|  null|     null|      15|   32225|\n",
      "|    10|     null|       3|    8750|\n",
      "|    10|    CLERK|       1|    1300|\n",
      "|    10|  MANAGER|       1|    2450|\n",
      "|    10|PRESIDENT|       1|    5000|\n",
      "|    20|     null|       5|   10875|\n",
      "|    20|  ANALYST|       2|    6000|\n",
      "|    20|    CLERK|       2|    1900|\n",
      "|    20|  MANAGER|       1|    2975|\n",
      "|    30|     null|       6|    9400|\n",
      "|    30|    CLERK|       1|     950|\n",
      "|    30|  MANAGER|       1|    2850|\n",
      "|    30| SALESMAN|       4|    5600|\n",
      "|    70|     null|       1|    3200|\n",
      "|    70|    CLERK|       1|    3200|\n",
      "+------+---------+--------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# rollup\n",
    "df.rollup('deptno','job').agg(count('*'),sum('sal')).orderBy('deptno','job').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "76570121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+--------+--------+\n",
      "|deptno|      job|max(sal)|min(sal)|\n",
      "+------+---------+--------+--------+\n",
      "|  null|     null|    5000|     800|\n",
      "|    10|     null|    5000|    1300|\n",
      "|    10|    CLERK|    1300|    1300|\n",
      "|    10|  MANAGER|    2450|    2450|\n",
      "|    10|PRESIDENT|    5000|    5000|\n",
      "|    20|     null|    3000|     800|\n",
      "|    20|  ANALYST|    3000|    3000|\n",
      "|    20|    CLERK|    1100|     800|\n",
      "|    20|  MANAGER|    2975|    2975|\n",
      "|    30|     null|    2850|     950|\n",
      "|    30|    CLERK|     950|     950|\n",
      "|    30|  MANAGER|    2850|    2850|\n",
      "|    30| SALESMAN|    1600|    1250|\n",
      "|    70|     null|    3200|    3200|\n",
      "|    70|    CLERK|    3200|    3200|\n",
      "+------+---------+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.rollup('deptno','job').agg(max('sal'), min('sal')).orderBy('deptno','job').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b1ba6c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+--------+--------+\n",
      "|deptno|      job|count(1)|sum(sal)|\n",
      "+------+---------+--------+--------+\n",
      "|  null|     null|      15|   32225|\n",
      "|  null|  ANALYST|       2|    6000|\n",
      "|  null|    CLERK|       5|    7350|\n",
      "|  null|  MANAGER|       3|    8275|\n",
      "|  null|PRESIDENT|       1|    5000|\n",
      "|  null| SALESMAN|       4|    5600|\n",
      "|    10|     null|       3|    8750|\n",
      "|    10|    CLERK|       1|    1300|\n",
      "|    10|  MANAGER|       1|    2450|\n",
      "|    10|PRESIDENT|       1|    5000|\n",
      "|    20|     null|       5|   10875|\n",
      "|    20|  ANALYST|       2|    6000|\n",
      "|    20|    CLERK|       2|    1900|\n",
      "|    20|  MANAGER|       1|    2975|\n",
      "|    30|     null|       6|    9400|\n",
      "|    30|    CLERK|       1|     950|\n",
      "|    30|  MANAGER|       1|    2850|\n",
      "|    30| SALESMAN|       4|    5600|\n",
      "|    70|     null|       1|    3200|\n",
      "|    70|    CLERK|       1|    3200|\n",
      "+------+---------+--------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 213:===========================================>         (163 + 3) / 200]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# cube\n",
    "df.cube('deptno','job').agg(count('*'), sum('sal')).orderBy('deptno','job').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "aa608619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+-------+-------+\n",
      "|deptno|      job|avg_sal|max_sal|\n",
      "+------+---------+-------+-------+\n",
      "|  null|     null|2148.33|   5000|\n",
      "|  null|  ANALYST| 3000.0|   3000|\n",
      "|  null|    CLERK| 1470.0|   3200|\n",
      "|  null|  MANAGER|2758.33|   2975|\n",
      "|  null|PRESIDENT| 5000.0|   5000|\n",
      "|  null| SALESMAN| 1400.0|   1600|\n",
      "|    10|     null|2916.67|   5000|\n",
      "|    10|    CLERK| 1300.0|   1300|\n",
      "|    10|  MANAGER| 2450.0|   2450|\n",
      "|    10|PRESIDENT| 5000.0|   5000|\n",
      "|    20|     null| 2175.0|   3000|\n",
      "|    20|  ANALYST| 3000.0|   3000|\n",
      "|    20|    CLERK|  950.0|   1100|\n",
      "|    20|  MANAGER| 2975.0|   2975|\n",
      "|    30|     null|1566.67|   2850|\n",
      "|    30|    CLERK|  950.0|    950|\n",
      "|    30|  MANAGER| 2850.0|   2850|\n",
      "|    30| SALESMAN| 1400.0|   1600|\n",
      "|    70|     null| 3200.0|   3200|\n",
      "|    70|    CLERK| 3200.0|   3200|\n",
      "+------+---------+-------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 217:===============================================>     (180 + 2) / 200]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.cube('deptno', 'job') \\\n",
    "    .agg(\n",
    "        count('*').alias('count'),\n",
    "        round(avg('sal'), 2).alias('avg_sal'),\n",
    "        max('sal').alias('max_sal')\n",
    "    ) \\\n",
    "    .orderBy('deptno', 'job') \\\n",
    "    .select('deptno', 'job', 'avg_sal', 'max_sal') \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9e919eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7909fd99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (spark_start)",
   "language": "python",
   "name": "spark_start"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
