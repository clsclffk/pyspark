{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d771d7e5",
   "metadata": {},
   "source": [
    "## 뉴욕시의 Yellow Taxi Trip데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "99d13dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('yellowtaxi_trip_count').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2444e3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "trip_files = '/trips/*'\n",
    "zone_files = 'taxi+_zone_lookup.csv'\n",
    "directory = os.path.join(os.getcwd(), 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bf393609",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "trips_df = spark.read.csv(f'file:///{directory}/{trip_files}',inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "21f224b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "zone_df = spark.read.csv(f'file:///{directory}/{zone_files}',inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a0d5f413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: string (nullable = true)\n",
      " |-- tpep_dropoff_datetime: string (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: integer (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trips_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cdcc98e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
      "|       2| 2021-03-01 00:22:02|  2021-03-01 00:23:22|              1|          0.0|         1|                 N|         264|         264|           2|        3.0|  0.5|    0.5|       0.0|         0.0|                  0.3|         4.3|                 0.0|\n",
      "|       2| 2021-03-01 00:24:48|  2021-03-01 00:24:56|              1|          0.0|         1|                 N|         152|         152|           2|        2.5|  0.5|    0.5|       0.0|         0.0|                  0.3|         3.8|                 0.0|\n",
      "|       2| 2021-03-01 00:25:17|  2021-03-01 00:31:01|              1|          0.0|         1|                 N|         152|         152|           2|        3.5|  0.5|    0.5|       0.0|         0.0|                  0.3|         4.8|                 0.0|\n",
      "|       1| 2021-03-01 00:07:40|  2021-03-01 00:31:23|              0|         16.5|         4|                 N|         138|         265|           1|       51.0|  0.5|    0.5|     11.65|        6.12|                  0.3|       70.07|                 0.0|\n",
      "|       2| 2021-03-01 00:02:13|  2021-03-01 00:06:01|              1|         1.13|         1|                 N|          68|         264|           1|        5.5|  0.5|    0.5|      1.86|         0.0|                  0.3|       11.16|                 2.5|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trips_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c50a35da",
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_df.createOrReplaceTempView('trips')\n",
    "zone_df.createOrReplaceTempView('zone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8d8cbf9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:===================================================>     (10 + 1) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+------------+-----------+------------+---------------+-------------+----------+------------+------------+-----------------+--------------+\n",
      "|VendorID|pickup_date|dropoff_date|pickup_time|dropoff_time|passenger_count|trip_distance|tip_amount|total_amount|payment_type|      pickup_zone|  dropoff_zone|\n",
      "+--------+-----------+------------+-----------+------------+---------------+-------------+----------+------------+------------+-----------------+--------------+\n",
      "|       2| 2021-03-01|  2021-03-01|          0|           0|              1|          0.0|       0.0|         4.3|           2|               NV|            NV|\n",
      "|       2| 2021-03-01|  2021-03-01|          0|           0|              1|          0.0|       0.0|         3.8|           2|   Manhattanville|Manhattanville|\n",
      "|       2| 2021-03-01|  2021-03-01|          0|           0|              1|          0.0|       0.0|         4.8|           2|   Manhattanville|Manhattanville|\n",
      "|       1| 2021-03-01|  2021-03-01|          0|           0|              0|         16.5|     11.65|       70.07|           1|LaGuardia Airport|            NA|\n",
      "|       2| 2021-03-01|  2021-03-01|          0|           0|              1|         1.13|      1.86|       11.16|           1|     East Chelsea|            NV|\n",
      "+--------+-----------+------------+-----------+------------+---------------+-------------+----------+------------+------------+-----------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "query = '''\n",
    "select\n",
    "t.VendorID,\n",
    "to_date(t.tpep_pickup_datetime) as pickup_date,\n",
    "to_date(t.tpep_dropoff_datetime) as dropoff_date,\n",
    "hour(t.tpep_dropoff_datetime) as pickup_time,\n",
    "hour(t.tpep_dropoff_datetime) as dropoff_time,\n",
    "t.passenger_count,\n",
    "t.trip_distance,\n",
    "t.tip_amount,\n",
    "t.total_amount,\n",
    "t.payment_type,\n",
    "pz.Zone as pickup_zone,\n",
    "dz.Zone as dropoff_zone\n",
    "from trips as t\n",
    "left join zone as pz\n",
    "on t.PULocationID = pz.LocationID\n",
    "left join zone as dz\n",
    "on t.DOLocationID = dz.LocationID\n",
    "'''\n",
    "\n",
    "df = spark.sql(query)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "485c03a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15000700"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bc443f",
   "metadata": {},
   "source": [
    "## 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80b64f1",
   "metadata": {},
   "source": [
    "## 열\n",
    "- **VendorID**: 택시 운행을 제공한 공급자의 식별자.\n",
    "- **pickup_date**: 택시 승차 일자 (tpep_pickup_datetime에서 변환된 날짜).\n",
    "- **dropoff_date**: 택시 하차 일자 (tpep_dropoff_datetime에서 변환된 날짜).\n",
    "- **pickup_time**: 승차 시간 (tpep_pickup_datetime에서 시간 추출).\n",
    "- **dropoff_time**: 하차 시간 (tpep_dropoff_datetime에서 시간 추출).\n",
    "- **passenger_count**: 탑승한 승객 수.\n",
    "- **trip_distance**: 여행의 총 거리 (마일 단위).\n",
    "- **tip_amount**: 승객이 지불한 팁 금액.\n",
    "- **total_amount**: 여행의 총 요금 (팁 포함).\n",
    "- **payment_type**: 결제 방법 (예: 카드, 현금 등).\n",
    "- **pickup_zone**: 택시 승차 지역 (zone 테이블에서 가져온 값).\n",
    "- **dropoff_zone**: 택시 하차 지역 (zone 테이블에서 가져온 값)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de03ca5b",
   "metadata": {},
   "source": [
    "## 중복 데이터 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ccc0ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16074"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count() - df.distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b2f1289",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropDuplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc460eb1",
   "metadata": {},
   "source": [
    "## 결측치 & 이상치 확인\n",
    "- VendorID, passenger_count, payment_type 열에 각각 834,028개의 null 값이 존재\n",
    "- 결측 비율은 약 5.56%\n",
    "- VendorID : 최빈값 대체\n",
    "- passenger_count : 0명은 이상치로 간주하여 제거, 중앙값 대체\n",
    "- payment_type : 최빈값 대체\n",
    "- tip_amount, total_amount 음수인 경우 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "571788be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 10:==================================================>     (10 + 1) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+------------+-----------+------------+---------------+-------------+----------+------------+------------+-----------+------------+\n",
      "|VendorID|pickup_date|dropoff_date|pickup_time|dropoff_time|passenger_count|trip_distance|tip_amount|total_amount|payment_type|pickup_zone|dropoff_zone|\n",
      "+--------+-----------+------------+-----------+------------+---------------+-------------+----------+------------+------------+-----------+------------+\n",
      "|  834028|          0|           0|          0|           0|         834028|            0|         0|           0|      834028|          0|           0|\n",
      "+--------+-----------+------------+-----------+------------+---------------+-------------+----------+------------+------------+-----------+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# 결측치 확인\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "null_counts = df.select(*[F.sum(F.when(F.col(c).isNull(), 1).otherwise(0)).alias(c)\n",
    "                         for c in df.columns])\n",
    "null_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "420dc8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 16:==================================================>     (10 + 1) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------------------+-----------------------+----------------------+-----------------------+--------------------------+------------------------+---------------------+-----------------------+-----------------------+----------------------+-----------------------+\n",
      "|VendorID_null_ratio|pickup_date_null_ratio|dropoff_date_null_ratio|pickup_time_null_ratio|dropoff_time_null_ratio|passenger_count_null_ratio|trip_distance_null_ratio|tip_amount_null_ratio|total_amount_null_ratio|payment_type_null_ratio|pickup_zone_null_ratio|dropoff_zone_null_ratio|\n",
      "+-------------------+----------------------+-----------------------+----------------------+-----------------------+--------------------------+------------------------+---------------------+-----------------------+-----------------------+----------------------+-----------------------+\n",
      "|0.05559927203397175|                   0.0|                    0.0|                   0.0|                    0.0|       0.05559927203397175|                     0.0|                  0.0|                    0.0|    0.05559927203397175|                   0.0|                    0.0|\n",
      "+-------------------+----------------------+-----------------------+----------------------+-----------------------+--------------------------+------------------------+---------------------+-----------------------+-----------------------+----------------------+-----------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# 결측치 비율\n",
    "total_rows = df.count()\n",
    "\n",
    "null_ratios = null_counts.select(\n",
    "            *[\n",
    "        (F.col(c) / total_rows).alias(f\"{c}_null_ratio\") \n",
    "        for c in null_counts.columns\n",
    "])\n",
    "\n",
    "null_ratios.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8f794db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+\n",
      "|summary|          VendorID|   passenger_count|      payment_type|\n",
      "+-------+------------------+------------------+------------------+\n",
      "|  count|          14150660|          14150660|          14150660|\n",
      "|   mean|1.6875516760348988|1.4257929312131024|1.2573771117389578|\n",
      "| stddev|0.4634915144829814|1.0446880103219505|0.4772950890499679|\n",
      "|    min|                 1|                 0|                 1|\n",
      "|    max|                 2|                 9|                 5|\n",
      "+-------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('VendorID','passenger_count','payment_type').describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ce9f904",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+\n",
      "|VendorID|  count|\n",
      "+--------+-------+\n",
      "|    null| 834028|\n",
      "|       1|4431189|\n",
      "|       2|9735483|\n",
      "+--------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# VendorID\n",
    "df.groupBy('VendorID').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22ed35c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna({'VendorID': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8bc3750",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------+\n",
      "|passenger_count|   count|\n",
      "+---------------+--------+\n",
      "|           null|  834028|\n",
      "|              1|10472413|\n",
      "|              6|  238647|\n",
      "|              3|  535718|\n",
      "|              5|  357257|\n",
      "|              9|      18|\n",
      "|              4|  202839|\n",
      "|              8|      22|\n",
      "|              7|      33|\n",
      "|              2| 2041604|\n",
      "|              0|  318121|\n",
      "+---------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# passenger_count\n",
    "df.groupBy('passenger_count').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "156c8531",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "median_passenger_count = df.approxQuantile('passenger_count', [0.5], 0.01)[0]  \n",
    "df = df.fillna({'passenger_count': median_passenger_count})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "721512de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter(df['passenger_count'] != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af59ad8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+\n",
      "|payment_type|   count|\n",
      "+------------+--------+\n",
      "|        null|  834028|\n",
      "|           1|10716903|\n",
      "|           3|   81434|\n",
      "|           5|       1|\n",
      "|           4|   59664|\n",
      "|           2| 3308670|\n",
      "+------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# payment_type\n",
    "df.groupBy('payment_type').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5909be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna({'payment_type': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "baffe501",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 17:==================================================>     (10 + 1) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|       tip_amount|\n",
      "+-------+-----------------+\n",
      "|  count|         15000700|\n",
      "|   mean|2.146797558780939|\n",
      "| stddev|2.610914434555077|\n",
      "|    min|          -333.32|\n",
      "|    max|          1140.44|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.select('tip_amount').describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a43fb41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1011"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(F.col('tip_amount') < 0).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82ac2b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14666030"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 팁 금액이 음수인 경우 제거\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "df = df.filter(F.col('tip_amount') >= 0)\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8487477f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 41:==================================================>     (10 + 1) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|        tip_amount|\n",
      "+-------+------------------+\n",
      "|  count|          14931876|\n",
      "|   mean|2.1567248181009013|\n",
      "| stddev| 2.609006208413183|\n",
      "|    min|               0.0|\n",
      "|    max|           1140.44|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.select(F.col('tip_amount')).describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d53d3cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 26:==================================================>     (10 + 1) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|      total_amount|\n",
      "+-------+------------------+\n",
      "|  count|          14999689|\n",
      "|   mean|18.757396086862318|\n",
      "| stddev| 145.7488478519927|\n",
      "|    min|            -647.8|\n",
      "|    max|          398469.2|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.select('total_amount').describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba8fbb49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "67813"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(F.col('total_amount') < 0).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0469df7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14594895"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 총 금액이 음수이거나 0인 경우 제거\n",
    "df = df.filter(F.col('total_amount') > 0)\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3d526858",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 38:==================================================>     (10 + 1) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|      total_amount|\n",
      "+-------+------------------+\n",
      "|  count|          14931876|\n",
      "|   mean|18.908677106800845|\n",
      "| stddev| 146.0575764264735|\n",
      "|    min|               0.0|\n",
      "|    max|          398469.2|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.select(F.col('total_amount')).describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cd2594",
   "metadata": {},
   "source": [
    "## 파생 변수 생성\n",
    "- tip_ratio 칼럼 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff701df6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 31:====================================================> (196 + 2) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+\n",
      "|summary|          tip_ratio|\n",
      "+-------+-------------------+\n",
      "|  count|           14594895|\n",
      "|   mean|0.11334367404538742|\n",
      "| stddev|0.08268506886335779|\n",
      "|    min|                0.0|\n",
      "|    max|                1.0|\n",
      "+-------+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# 팁의 비율(팁/총 금액) 컬럼 추가 \n",
    "df = df.withColumn('tip_ratio',F.col('tip_amount') / F.col('total_amount'))\n",
    "df.select(F.col('tip_ratio')).describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21bc627c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 35:===================================================>  (192 + 2) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|null_count|\n",
      "+----------+\n",
      "|         0|\n",
      "+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 35:=====================================================>(197 + 2) / 200]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "null_count_tip_ratio = df.select(\n",
    "    F.sum(F.when(F.col('tip_ratio').isNull(), 1).otherwise(0)).alias('null_count')\n",
    ")\n",
    "\n",
    "null_count_tip_ratio.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1d5017",
   "metadata": {},
   "source": [
    "## 상관계수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c826911a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = false)\n",
      " |-- pickup_date: date (nullable = true)\n",
      " |-- dropoff_date: date (nullable = true)\n",
      " |-- pickup_time: integer (nullable = true)\n",
      " |-- dropoff_time: integer (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- payment_type: integer (nullable = false)\n",
      " |-- pickup_zone: string (nullable = true)\n",
      " |-- dropoff_zone: string (nullable = true)\n",
      " |-- tip_ratio: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "551a703c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/16 11:27:48 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "24/12/16 11:27:48 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseMatrix([[ 1.00000000e+00,  5.39075142e-02,  4.22992711e-04,\n",
      "               6.34515553e-01],\n",
      "             [ 5.39075142e-02,  1.00000000e+00,  1.13608863e-03,\n",
      "               9.70655138e-04],\n",
      "             [ 4.22992711e-04,  1.13608863e-03,  1.00000000e+00,\n",
      "              -5.47965311e-03],\n",
      "             [ 6.34515553e-01,  9.70655138e-04, -5.47965311e-03,\n",
      "               1.00000000e+00]])\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.stat import Correlation\n",
    "\n",
    "numeric_columns = ['tip_amount', 'total_amount', 'trip_distance', 'tip_ratio'] \n",
    "assembler = VectorAssembler(inputCols=numeric_columns, outputCol='features')\n",
    "\n",
    "# 벡터화된 데이터를 생성\n",
    "df_vec = assembler.transform(df)\n",
    "\n",
    "# 상관행렬 계산\n",
    "correlation_matrix = Correlation.corr(df_vec, 'features').head()[0]  \n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9d070748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               tip_amount  total_amount  trip_distance  tip_ratio\n",
      "tip_amount       1.000000      0.053908       0.000423   0.634516\n",
      "total_amount     0.053908      1.000000       0.001136   0.000971\n",
      "trip_distance    0.000423      0.001136       1.000000  -0.005480\n",
      "tip_ratio        0.634516      0.000971      -0.005480   1.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "correlation_array = correlation_matrix.toArray()\n",
    "correlation_df = pd.DataFrame(correlation_array, columns=numeric_columns, index=numeric_columns)\n",
    "print(correlation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "33daf699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tip_ratio 칼럼 제거\n",
    "df = df.drop('tip_ratio')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f768ea89",
   "metadata": {},
   "source": [
    "## dropoff_zone, pickup_zone 변수 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cee78620",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 112:====================================================>(199 + 1) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|        dropoff_zone| count|\n",
      "+--------------------+------+\n",
      "|           Homecrest|  4314|\n",
      "|Governor's Island...|     7|\n",
      "|              Corona|  6792|\n",
      "|    Bensonhurst West|  4420|\n",
      "|         Westerleigh|   224|\n",
      "|      Newark Airport| 17319|\n",
      "|Charleston/Totten...|   825|\n",
      "|          Douglaston|  2035|\n",
      "|          Mount Hope|  6515|\n",
      "|East Concourse/Co...| 11984|\n",
      "|      Pelham Parkway|  4114|\n",
      "|         Marble Hill|  1285|\n",
      "|           Rego Park|  7604|\n",
      "|Upper East Side S...|659445|\n",
      "|       Dyker Heights|  2614|\n",
      "|Heartland Village...|   397|\n",
      "|   Kew Gardens Hills|  5333|\n",
      "|     Jackson Heights| 24488|\n",
      "|             Bayside|  3538|\n",
      "|      Yorkville West|348092|\n",
      "+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"dropoff_zone\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dec41b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|         pickup_zone| count|\n",
      "+--------------------+------+\n",
      "|           Homecrest|  1922|\n",
      "|Governor's Island...|     7|\n",
      "|              Corona|  2280|\n",
      "|    Bensonhurst West|  2064|\n",
      "|         Westerleigh|    28|\n",
      "|Charleston/Totten...|   713|\n",
      "|      Newark Airport|   739|\n",
      "|          Douglaston|   860|\n",
      "|East Concourse/Co...|  4112|\n",
      "|      Pelham Parkway|  2041|\n",
      "|          Mount Hope|  2859|\n",
      "|         Marble Hill|   626|\n",
      "|           Rego Park|  2590|\n",
      "|Upper East Side S...|757472|\n",
      "|       Dyker Heights|   743|\n",
      "|Heartland Village...|   145|\n",
      "|   Kew Gardens Hills|  1814|\n",
      "|       Rikers Island|     6|\n",
      "|             Bayside|  1257|\n",
      "|     Jackson Heights|  5949|\n",
      "+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"pickup_zone\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d4e4dafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('dropoff_zone','pickup_zone')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4886da",
   "metadata": {},
   "source": [
    "## pickup_date, dropoff_date 칼럼 제거\n",
    "- 주말인지 여부 파생변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "28c68899",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|pickup_date|count|\n",
      "+-----------+-----+\n",
      "| 2021-06-22|96228|\n",
      "| 2021-01-27|51295|\n",
      "| 2021-05-12|84766|\n",
      "| 2021-07-30|96221|\n",
      "| 2021-07-20|89403|\n",
      "| 2021-04-29|80247|\n",
      "| 2021-07-17|92299|\n",
      "| 2021-07-23|96209|\n",
      "| 2021-04-24|76788|\n",
      "| 2009-01-01|  103|\n",
      "| 2021-02-15|39291|\n",
      "| 2021-03-22|58303|\n",
      "| 2021-05-03|73349|\n",
      "| 2021-07-19|86298|\n",
      "| 2021-01-18|36135|\n",
      "| 2021-01-25|46181|\n",
      "| 2021-02-02|28437|\n",
      "| 2021-07-10|91140|\n",
      "| 2021-06-04|92975|\n",
      "| 2021-04-25|48149|\n",
      "+-----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby('pickup_date').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6ea1bceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------------+\n",
      "|min_pickup_date|max_pickup_date|\n",
      "+---------------+---------------+\n",
      "|     2004-04-04|     2029-05-05|\n",
      "+---------------+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 146:===================================================> (196 + 2) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------------+\n",
      "|min_dropoff_date|max_dropoff_date|\n",
      "+----------------+----------------+\n",
      "|      2004-04-05|      2029-05-05|\n",
      "+----------------+----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "pickup_date_range = df.select(F.min(\"pickup_date\").alias(\"min_pickup_date\"),\n",
    "                              F.max(\"pickup_date\").alias(\"max_pickup_date\")).show()\n",
    "\n",
    "dropoff_date_range = df.select(F.min(\"dropoff_date\").alias(\"min_dropoff_date\"),\n",
    "                               F.max(\"dropoff_date\").alias(\"max_dropoff_date\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "98c9115b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'pickup_date'와 'dropoff_date'에서 요일 추출 (1=월요일, 7=일요일)\n",
    "df = df.withColumn(\"pickup_day_of_week\", F.dayofweek(df[\"pickup_date\"]))\n",
    "df = df.withColumn(\"dropoff_day_of_week\", F.dayofweek(df[\"dropoff_date\"]))\n",
    "\n",
    "# 주말인지 아닌지를 나타내는 파생변수 생성 (주말이면 1, 아니면 0)\n",
    "df = df.withColumn(\"is_pickup_weekend\", F.when((df[\"pickup_day_of_week\"] == 6) | (df[\"pickup_day_of_week\"] == 7), 1).otherwise(0))\n",
    "df = df.withColumn(\"is_dropoff_weekend\", F.when((df[\"dropoff_day_of_week\"] == 6) | (df[\"dropoff_day_of_week\"] == 7), 1).otherwise(0))\n",
    "\n",
    "# 이제 'pickup_day_of_week'와 'dropoff_day_of_week' 칼럼 삭제\n",
    "df = df.drop(\"pickup_day_of_week\", \"dropoff_day_of_week\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a0843b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('pickup_date','dropoff_date')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581b1ecd",
   "metadata": {},
   "source": [
    "## 뷰 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5df5a70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('comb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8675a6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 38:==================================================>     (10 + 1) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+\n",
      "|pickup_date|pickup_time|\n",
      "+-----------+-----------+\n",
      "| 2021-03-07|          1|\n",
      "| 2021-03-13|          1|\n",
      "| 2021-03-05|          1|\n",
      "| 2021-03-06|          1|\n",
      "| 2021-03-13|          1|\n",
      "| 2021-03-11|          1|\n",
      "| 2021-03-12|          1|\n",
      "| 2021-03-20|          1|\n",
      "| 2021-03-12|          1|\n",
      "| 2021-03-06|          1|\n",
      "| 2021-03-21|          1|\n",
      "| 2021-03-24|          1|\n",
      "| 2021-03-02|          1|\n",
      "| 2021-03-17|          1|\n",
      "| 2021-03-16|          1|\n",
      "| 2021-03-03|          1|\n",
      "| 2021-03-13|          1|\n",
      "| 2021-03-07|          1|\n",
      "| 2021-03-13|          1|\n",
      "| 2021-03-18|          1|\n",
      "+-----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "query = '''\n",
    "select pickup_date, pickup_time \n",
    "from comb \n",
    "where pickup_time>0\n",
    "'''\n",
    "\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85a77c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 41:==================================================>     (10 + 1) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+\n",
      "|pickup_date|pickup_time|\n",
      "+-----------+-----------+\n",
      "| 2009-01-01|         21|\n",
      "| 2009-01-01|         16|\n",
      "| 2009-01-01|          0|\n",
      "| 2009-01-01|          0|\n",
      "| 2009-01-01|          0|\n",
      "| 2009-01-01|          0|\n",
      "| 2009-01-01|          0|\n",
      "| 2009-01-01|          2|\n",
      "| 2008-12-31|         13|\n",
      "| 2009-01-01|          1|\n",
      "| 2009-01-01|          0|\n",
      "| 2009-01-01|          3|\n",
      "| 2008-12-31|         23|\n",
      "| 2009-01-01|          0|\n",
      "| 2009-01-01|          8|\n",
      "| 2009-01-01|          2|\n",
      "| 2008-12-31|         23|\n",
      "| 2009-01-01|          0|\n",
      "| 2009-01-01|          0|\n",
      "| 2009-01-01|          0|\n",
      "+-----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "query = '''\n",
    "select pickup_date, pickup_time \n",
    "from comb \n",
    "where pickup_date<'2020-12-31'\n",
    "'''\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5feebfcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(4) HashAggregate(keys=[dropoff_time#79, trip_distance#20, pickup_date#76, dropoff_date#77, VendorID#16, pickup_time#78, tip_amount#29, pickup_zone#80, payment_type#25, passenger_count#19, dropoff_zone#81, total_amount#32], functions=[])\n",
      "+- Exchange hashpartitioning(dropoff_time#79, trip_distance#20, pickup_date#76, dropoff_date#77, VendorID#16, pickup_time#78, tip_amount#29, pickup_zone#80, payment_type#25, passenger_count#19, dropoff_zone#81, total_amount#32, 200), ENSURE_REQUIREMENTS, [id=#1900]\n",
      "   +- *(3) HashAggregate(keys=[dropoff_time#79, knownfloatingpointnormalized(normalizenanandzero(trip_distance#20)) AS trip_distance#20, pickup_date#76, dropoff_date#77, VendorID#16, pickup_time#78, knownfloatingpointnormalized(normalizenanandzero(tip_amount#29)) AS tip_amount#29, pickup_zone#80, payment_type#25, passenger_count#19, dropoff_zone#81, knownfloatingpointnormalized(normalizenanandzero(total_amount#32)) AS total_amount#32], functions=[])\n",
      "      +- *(3) Project [VendorID#16, cast(tpep_pickup_datetime#17 as date) AS pickup_date#76, cast(tpep_dropoff_datetime#18 as date) AS dropoff_date#77, hour(cast(tpep_dropoff_datetime#18 as timestamp), Some(Asia/Seoul)) AS pickup_time#78, hour(cast(tpep_dropoff_datetime#18 as timestamp), Some(Asia/Seoul)) AS dropoff_time#79, passenger_count#19, trip_distance#20, tip_amount#29, total_amount#32, payment_type#25, Zone#70 AS pickup_zone#80, Zone#84 AS dropoff_zone#81]\n",
      "         +- *(3) BroadcastHashJoin [DOLocationID#24], [LocationID#82], LeftOuter, BuildRight, false\n",
      "            :- *(3) Project [VendorID#16, tpep_pickup_datetime#17, tpep_dropoff_datetime#18, passenger_count#19, trip_distance#20, DOLocationID#24, payment_type#25, tip_amount#29, total_amount#32, Zone#70]\n",
      "            :  +- *(3) BroadcastHashJoin [PULocationID#23], [LocationID#68], LeftOuter, BuildRight, false\n",
      "            :     :- *(3) Filter ((((((isnotnull(tip_amount#29) AND isnotnull(total_amount#32)) AND isnotnull(tpep_pickup_datetime#17)) AND NOT (coalesce(passenger_count#19, 1) = 0)) AND (tip_amount#29 >= 0.0)) AND (total_amount#32 >= 0.0)) AND (cast(tpep_pickup_datetime#17 as date) < 18627))\n",
      "            :     :  +- FileScan csv [VendorID#16,tpep_pickup_datetime#17,tpep_dropoff_datetime#18,passenger_count#19,trip_distance#20,PULocationID#23,DOLocationID#24,payment_type#25,tip_amount#29,total_amount#32] Batched: false, DataFilters: [isnotnull(tip_amount#29), isnotnull(total_amount#32), isnotnull(tpep_pickup_datetime#17), NOT (c..., Format: CSV, Location: InMemoryFileIndex[file:/home/lab11/src/data/trips/yellow_tripdata_2021-01.csv, file:/home/lab11/s..., PartitionFilters: [], PushedFilters: [IsNotNull(tip_amount), IsNotNull(total_amount), IsNotNull(tpep_pickup_datetime), GreaterThanOrEq..., ReadSchema: struct<VendorID:int,tpep_pickup_datetime:string,tpep_dropoff_datetime:string,passenger_count:int,...\n",
      "            :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [id=#1865]\n",
      "            :        +- *(1) Filter isnotnull(LocationID#68)\n",
      "            :           +- FileScan csv [LocationID#68,Zone#70] Batched: false, DataFilters: [isnotnull(LocationID#68)], Format: CSV, Location: InMemoryFileIndex[file:/home/lab11/src/data/taxi+_zone_lookup.csv], PartitionFilters: [], PushedFilters: [IsNotNull(LocationID)], ReadSchema: struct<LocationID:int,Zone:string>\n",
      "            +- ReusedExchange [LocationID#82, Zone#84], BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [id=#1865]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(query).explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4c87d650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(4) HashAggregate(keys=[dropoff_time#79, trip_distance#20, pickup_date#76, dropoff_date#77, VendorID#16, pickup_time#78, tip_amount#29, pickup_zone#80, payment_type#25, passenger_count#19, dropoff_zone#81, total_amount#32], functions=[])\n",
      "+- Exchange hashpartitioning(dropoff_time#79, trip_distance#20, pickup_date#76, dropoff_date#77, VendorID#16, pickup_time#78, tip_amount#29, pickup_zone#80, payment_type#25, passenger_count#19, dropoff_zone#81, total_amount#32, 200), ENSURE_REQUIREMENTS, [id=#2007]\n",
      "   +- *(3) HashAggregate(keys=[dropoff_time#79, knownfloatingpointnormalized(normalizenanandzero(trip_distance#20)) AS trip_distance#20, pickup_date#76, dropoff_date#77, VendorID#16, pickup_time#78, knownfloatingpointnormalized(normalizenanandzero(tip_amount#29)) AS tip_amount#29, pickup_zone#80, payment_type#25, passenger_count#19, dropoff_zone#81, knownfloatingpointnormalized(normalizenanandzero(total_amount#32)) AS total_amount#32], functions=[])\n",
      "      +- *(3) Project [VendorID#16, cast(tpep_pickup_datetime#17 as date) AS pickup_date#76, cast(tpep_dropoff_datetime#18 as date) AS dropoff_date#77, hour(cast(tpep_dropoff_datetime#18 as timestamp), Some(Asia/Seoul)) AS pickup_time#78, hour(cast(tpep_dropoff_datetime#18 as timestamp), Some(Asia/Seoul)) AS dropoff_time#79, passenger_count#19, trip_distance#20, tip_amount#29, total_amount#32, payment_type#25, Zone#70 AS pickup_zone#80, Zone#84 AS dropoff_zone#81]\n",
      "         +- *(3) BroadcastHashJoin [DOLocationID#24], [LocationID#82], LeftOuter, BuildRight, false\n",
      "            :- *(3) Project [VendorID#16, tpep_pickup_datetime#17, tpep_dropoff_datetime#18, passenger_count#19, trip_distance#20, DOLocationID#24, payment_type#25, tip_amount#29, total_amount#32, Zone#70]\n",
      "            :  +- *(3) BroadcastHashJoin [PULocationID#23], [LocationID#68], LeftOuter, BuildRight, false\n",
      "            :     :- *(3) Filter (((((((isnotnull(tip_amount#29) AND isnotnull(total_amount#32)) AND isnotnull(tpep_dropoff_datetime#18)) AND NOT (coalesce(passenger_count#19, 1) = 0)) AND (tip_amount#29 >= 0.0)) AND (total_amount#32 >= 0.0)) AND (hour(cast(tpep_dropoff_datetime#18 as timestamp), Some(Asia/Seoul)) > 0)) AND (hour(cast(tpep_dropoff_datetime#18 as timestamp), Some(Asia/Seoul)) <= 12))\n",
      "            :     :  +- FileScan csv [VendorID#16,tpep_pickup_datetime#17,tpep_dropoff_datetime#18,passenger_count#19,trip_distance#20,PULocationID#23,DOLocationID#24,payment_type#25,tip_amount#29,total_amount#32] Batched: false, DataFilters: [isnotnull(tip_amount#29), isnotnull(total_amount#32), isnotnull(tpep_dropoff_datetime#18), NOT (..., Format: CSV, Location: InMemoryFileIndex[file:/home/lab11/src/data/trips/yellow_tripdata_2021-01.csv, file:/home/lab11/s..., PartitionFilters: [], PushedFilters: [IsNotNull(tip_amount), IsNotNull(total_amount), IsNotNull(tpep_dropoff_datetime), GreaterThanOrE..., ReadSchema: struct<VendorID:int,tpep_pickup_datetime:string,tpep_dropoff_datetime:string,passenger_count:int,...\n",
      "            :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [id=#1972]\n",
      "            :        +- *(1) Filter isnotnull(LocationID#68)\n",
      "            :           +- FileScan csv [LocationID#68,Zone#70] Batched: false, DataFilters: [isnotnull(LocationID#68)], Format: CSV, Location: InMemoryFileIndex[file:/home/lab11/src/data/taxi+_zone_lookup.csv], PartitionFilters: [], PushedFilters: [IsNotNull(LocationID)], ReadSchema: struct<LocationID:int,Zone:string>\n",
      "            +- ReusedExchange [LocationID#82, Zone#84], BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [id=#1972]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query2 = '''\n",
    "select pickup_date, pickup_time \n",
    "from comb \n",
    "where pickup_time > 0 and pickup_time<=12\n",
    "'''\n",
    "spark.sql(query2).explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "65e5f433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(6) Sort [pickup_date#76 ASC NULLS FIRST], true, 0\n",
      "+- Exchange rangepartitioning(pickup_date#76 ASC NULLS FIRST, 200), ENSURE_REQUIREMENTS, [id=#2153]\n",
      "   +- *(5) HashAggregate(keys=[pickup_date#76], functions=[count(1)])\n",
      "      +- Exchange hashpartitioning(pickup_date#76, 200), ENSURE_REQUIREMENTS, [id=#2149]\n",
      "         +- *(4) HashAggregate(keys=[pickup_date#76], functions=[partial_count(1)])\n",
      "            +- *(4) HashAggregate(keys=[dropoff_time#79, trip_distance#20, pickup_date#76, dropoff_date#77, VendorID#16, pickup_time#78, tip_amount#29, pickup_zone#80, payment_type#25, passenger_count#19, dropoff_zone#81, total_amount#32], functions=[])\n",
      "               +- Exchange hashpartitioning(dropoff_time#79, trip_distance#20, pickup_date#76, dropoff_date#77, VendorID#16, pickup_time#78, tip_amount#29, pickup_zone#80, payment_type#25, passenger_count#19, dropoff_zone#81, total_amount#32, 200), ENSURE_REQUIREMENTS, [id=#2144]\n",
      "                  +- *(3) HashAggregate(keys=[dropoff_time#79, knownfloatingpointnormalized(normalizenanandzero(trip_distance#20)) AS trip_distance#20, pickup_date#76, dropoff_date#77, VendorID#16, pickup_time#78, knownfloatingpointnormalized(normalizenanandzero(tip_amount#29)) AS tip_amount#29, pickup_zone#80, payment_type#25, passenger_count#19, dropoff_zone#81, knownfloatingpointnormalized(normalizenanandzero(total_amount#32)) AS total_amount#32], functions=[])\n",
      "                     +- *(3) Project [VendorID#16, cast(tpep_pickup_datetime#17 as date) AS pickup_date#76, cast(tpep_dropoff_datetime#18 as date) AS dropoff_date#77, hour(cast(tpep_dropoff_datetime#18 as timestamp), Some(Asia/Seoul)) AS pickup_time#78, hour(cast(tpep_dropoff_datetime#18 as timestamp), Some(Asia/Seoul)) AS dropoff_time#79, passenger_count#19, trip_distance#20, tip_amount#29, total_amount#32, payment_type#25, Zone#70 AS pickup_zone#80, Zone#84 AS dropoff_zone#81]\n",
      "                        +- *(3) BroadcastHashJoin [DOLocationID#24], [LocationID#82], LeftOuter, BuildRight, false\n",
      "                           :- *(3) Project [VendorID#16, tpep_pickup_datetime#17, tpep_dropoff_datetime#18, passenger_count#19, trip_distance#20, DOLocationID#24, payment_type#25, tip_amount#29, total_amount#32, Zone#70]\n",
      "                           :  +- *(3) BroadcastHashJoin [PULocationID#23], [LocationID#68], LeftOuter, BuildRight, false\n",
      "                           :     :- *(3) Filter ((((((isnotnull(tip_amount#29) AND isnotnull(total_amount#32)) AND isnotnull(tpep_dropoff_datetime#18)) AND NOT (coalesce(passenger_count#19, 1) = 0)) AND (tip_amount#29 >= 0.0)) AND (total_amount#32 >= 0.0)) AND (hour(cast(tpep_dropoff_datetime#18 as timestamp), Some(Asia/Seoul)) > 0))\n",
      "                           :     :  +- FileScan csv [VendorID#16,tpep_pickup_datetime#17,tpep_dropoff_datetime#18,passenger_count#19,trip_distance#20,PULocationID#23,DOLocationID#24,payment_type#25,tip_amount#29,total_amount#32] Batched: false, DataFilters: [isnotnull(tip_amount#29), isnotnull(total_amount#32), isnotnull(tpep_dropoff_datetime#18), NOT (..., Format: CSV, Location: InMemoryFileIndex[file:/home/lab11/src/data/trips/yellow_tripdata_2021-01.csv, file:/home/lab11/s..., PartitionFilters: [], PushedFilters: [IsNotNull(tip_amount), IsNotNull(total_amount), IsNotNull(tpep_dropoff_datetime), GreaterThanOrE..., ReadSchema: struct<VendorID:int,tpep_pickup_datetime:string,tpep_dropoff_datetime:string,passenger_count:int,...\n",
      "                           :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [id=#2100]\n",
      "                           :        +- *(1) Filter isnotnull(LocationID#68)\n",
      "                           :           +- FileScan csv [LocationID#68,Zone#70] Batched: false, DataFilters: [isnotnull(LocationID#68)], Format: CSV, Location: InMemoryFileIndex[file:/home/lab11/src/data/taxi+_zone_lookup.csv], PartitionFilters: [], PushedFilters: [IsNotNull(LocationID)], ReadSchema: struct<LocationID:int,Zone:string>\n",
      "                           +- ReusedExchange [LocationID#82, Zone#84], BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [id=#2100]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query3 = '''\n",
    "select pickup_date , count(*) as trip_count\n",
    "from comb \n",
    "where pickup_time > 0\n",
    "group by pickup_date\n",
    "order by pickup_date\n",
    "'''\n",
    "spark.sql(query3).explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d584107",
   "metadata": {},
   "source": [
    "## 운행 거리와 요금의 상관관계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b951138b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 51:====================================================> (193 + 2) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|         correlation|\n",
      "+--------------------+\n",
      "|0.001136088625537...|\n",
      "+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 51:=====================================================>(198 + 2) / 200]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "query = '''\n",
    "select corr(trip_distance, total_amount) as correlation\n",
    "from comb\n",
    "'''\n",
    "\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21cb781",
   "metadata": {},
   "source": [
    "## 피크 시간대 요금 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cbadd4d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 56:=============================================>        (170 + 2) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+--------------------+\n",
      "|pickup_time|counting|          total_fare|\n",
      "+-----------+--------+--------------------+\n",
      "|         18| 1090676|2.1214896040000785E7|\n",
      "|         15| 1057248|1.9345986820000723E7|\n",
      "|         17| 1054550|2.0898812310000747E7|\n",
      "|         14| 1019788| 1.817586856000068E7|\n",
      "|         16| 1017955|1.9940757080000717E7|\n",
      "|         13|  959324|1.7323265730000548E7|\n",
      "|         19|  950564|1.8294262630000595E7|\n",
      "|         12|  929874|1.6655357440000482E7|\n",
      "|         11|  829942|1.4493488710000403E7|\n",
      "|         10|  755816|1.3230574760000302E7|\n",
      "|         20|  719753|1.3683735260000315E7|\n",
      "|          9|  684362|1.2198736130000228E7|\n",
      "|         21|  613558|1.1972544470000198E7|\n",
      "|          8|  590053|1.0542565370000144E7|\n",
      "|         22|  547719|1.1058150650000159E7|\n",
      "|         23|  442166|    9448824.75000007|\n",
      "|          7|  380850|   7153067.109999945|\n",
      "|          0|  299802|   6790455.609999943|\n",
      "|          6|  199243|  3988966.4499999736|\n",
      "|          1|  174970|  3931215.0499999723|\n",
      "+-----------+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# 시간대별 승차건수, 요금 \n",
    "query = '''\n",
    "SELECT pickup_time, COUNT(*) AS counting, SUM(total_amount) AS total_fare\n",
    "FROM comb\n",
    "GROUP BY pickup_time\n",
    "ORDER BY counting DESC\n",
    "''' \n",
    "\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ad36d3",
   "metadata": {},
   "source": [
    "## 지불 유형별 요금, 팁 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06a62414",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 59:====================================================> (194 + 2) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------------+--------------------+\n",
      "|payment_type|         total_fare|                 tip|\n",
      "+------------+-------------------+--------------------+\n",
      "|           1|2.246290602700514E8|3.1532255180000182E7|\n",
      "|           2|5.009360277998641E7|              277.31|\n",
      "|           3| 1608725.3299999977|               50.42|\n",
      "|           4|  345319.1099999997|                 6.1|\n",
      "+------------+-------------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 60:==========================================>           (159 + 2) / 200]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "query = '''\n",
    "SELECT payment_type, SUM(total_amount) AS total_fare, SUM(tip_amount) AS tip\n",
    "FROM comb\n",
    "GROUP BY payment_type\n",
    "ORDER BY total_fare DESC\n",
    "''' \n",
    "\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523746d5",
   "metadata": {},
   "source": [
    "## 승차지역/하차지역별 평균거리, 요금"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "14521d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 64:=================================================>    (183 + 2) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+\n",
      "|      avg_distance|          avg_fare|\n",
      "+------------------+------------------+\n",
      "|         205266.12|             47.63|\n",
      "|         167305.08|              76.0|\n",
      "|         131123.07|             61.18|\n",
      "|          77093.46|             19.04|\n",
      "|         70968.425|             53.22|\n",
      "|        65796.0925|32.072500000000005|\n",
      "|          63336.38|50.620000000000005|\n",
      "|          56564.13|             51.08|\n",
      "|          54215.12|33.269999999999996|\n",
      "|52683.263333333336| 49.25666666666666|\n",
      "|49552.270000000004|            70.025|\n",
      "|         45886.492|             51.65|\n",
      "| 41189.96666666667|             59.79|\n",
      "|        32914.5775|26.325000000000003|\n",
      "|          31690.14|53.605000000000004|\n",
      "|        31568.9575|           71.5875|\n",
      "|29940.403333333335|40.803333333333335|\n",
      "| 29903.07666666667|             53.49|\n",
      "|29279.048749999998| 51.75625000000001|\n",
      "|28037.878000000004| 40.12800000000001|\n",
      "+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "query = '''\n",
    "SELECT AVG(trip_distance) AS avg_distance,\n",
    "        AVG(total_amount) AS avg_fare\n",
    "FROM comb\n",
    "GROUP BY pickup_zone, dropoff_zone\n",
    "ORDER BY avg_distance DESC\n",
    "''' \n",
    "\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce6dd59",
   "metadata": {},
   "source": [
    "## 팁의 비율에 따른 거리, 여행 건수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e4cbdef",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 68:==============================================>       (172 + 2) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+--------------------+------------------+\n",
      "|           tip_ratio|trip_count|      total_distance|      avg_distance|\n",
      "+--------------------+----------+--------------------+------------------+\n",
      "|                 0.0|   4208688|5.4922750050000034E7|13.049850701691367|\n",
      "|2.379196307487331E-5|         1|                 0.0|               0.0|\n",
      "|3.024071610015725...|         1|                62.4|              62.4|\n",
      "|3.251398101183509E-5|         1|               67.87|             67.87|\n",
      "|3.329892444474043...|         1|                 0.0|               0.0|\n",
      "|3.698772007693446E-5|         1|               58.23|             58.23|\n",
      "|4.992261993909440...|         2|                 0.0|               0.0|\n",
      "|5.003502451716201...|         1|               50.56|             50.56|\n",
      "|5.076915266284206E-5|         1|                 0.0|               0.0|\n",
      "|5.553395901593825E-5|         1|                 0.0|               0.0|\n",
      "|5.569169079973268E-5|         1|               32.74|             32.74|\n",
      "|5.704181164793794E-5|         1|                 0.0|               0.0|\n",
      "|5.741187277528993E-5|         1|               30.27|             30.27|\n",
      "| 5.81192607230036E-5|         1|                36.1|              36.1|\n",
      "|5.861321141785358...|         1|                45.9|              45.9|\n",
      "|6.194443584105058E-5|         1|               84.51|             84.51|\n",
      "|6.237914041544508E-5|         1|                 0.0|               0.0|\n",
      "|6.385288295766553E-5|         1|                49.1|              49.1|\n",
      "|6.496459429610862E-5|         1|                22.4|              22.4|\n",
      "|6.593696426216537E-5|         1|               44.77|             44.77|\n",
      "+--------------------+----------+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 68:=====================================================>(198 + 2) / 200]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# 팁 비율별 여행 건수와 총 거리와 거리 평균\n",
    "query = '''\n",
    "SELECT \n",
    "    tip_ratio,\n",
    "    COUNT(*) AS trip_count,\n",
    "    SUM(trip_distance) AS total_distance,\n",
    "    AVG(trip_distance) AS avg_distance\n",
    "FROM \n",
    "    comb\n",
    "GROUP BY \n",
    "    tip_ratio\n",
    "ORDER BY \n",
    "    tip_ratio\n",
    "''' \n",
    "\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abec4f45",
   "metadata": {},
   "source": [
    "## 총 요금 예측 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "407bb19a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = false)\n",
      " |-- pickup_time: integer (nullable = true)\n",
      " |-- dropoff_time: integer (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- payment_type: integer (nullable = false)\n",
      " |-- is_pickup_weekend: integer (nullable = false)\n",
      " |-- is_dropoff_weekend: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6bd5c05f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/16 12:57:53 WARN Instrumentation: [5c06a51f] regParam is zero, which might cause numerical instability and overfitting.\n",
      "24/12/16 13:01:00 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK\n",
      "24/12/16 13:01:00 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK\n",
      "24/12/16 13:01:00 WARN Instrumentation: [5c06a51f] Cholesky solver failed due to singular covariance matrix. Retrying with Quasi-Newton solver.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------+--------------------+\n",
      "|        prediction|total_amount|            features|\n",
      "+------------------+------------+--------------------+\n",
      "|27.062506913121258|        10.3|(62,[20,43,49,59]...|\n",
      "| 11.81892595463748|        29.0|(62,[20,43,49,57,...|\n",
      "| 11.81892595463748|       53.12|(62,[20,43,49,57,...|\n",
      "|16.473135535283358|        8.15|(62,[0,1,20,43,49...|\n",
      "|19.231205517917118|        9.45|(62,[0,1,20,43,49...|\n",
      "|17.156575536809616|        9.95|(62,[0,1,20,43,49...|\n",
      "|16.858230372080165|         8.3|(62,[0,20,43,49,5...|\n",
      "|18.714149660383466|        10.8|(62,[0,1,20,43,49...|\n",
      "|18.197069428269018|       11.15|(62,[0,1,20,43,49...|\n",
      "|18.535683651868872|       12.35|(62,[0,1,20,43,49...|\n",
      "+------------------+------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 238:====================================================>(198 + 2) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231.9382230804608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "train, test = df.randomSplit([0.8,0.2], seed=42)\n",
    "\n",
    "num_features = ['trip_distance','tip_amount']\n",
    "cat_features = ['VendorID', 'pickup_time','dropoff_time','passenger_count',\n",
    "               'payment_type','is_pickup_weekend','is_dropoff_weekend']\n",
    "target = 'total_amount'\n",
    "\n",
    "# StringIndexer를 사용하여 범주형 변수들을 인덱스로 변환\n",
    "indexers = [StringIndexer(inputCol=col, outputCol=col + \"_index\") for col in cat_features]\n",
    "\n",
    "# 원-핫 인코딩\n",
    "encoders = [OneHotEncoder(inputCol=col + \"_index\", outputCol=col + \"_onehot\") for col in cat_features]\n",
    "\n",
    "# 벡터화\n",
    "assembler = VectorAssembler(inputCols=num_features + [col + \"_onehot\" for col in cat_features], outputCol=\"features\")\n",
    "\n",
    "# 선형 회귀 모델 정의\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=target)\n",
    "\n",
    "# 파이프라인 정의\n",
    "pipeline = Pipeline(stages=indexers + encoders + [assembler, lr])\n",
    "\n",
    "# 모델 학습\n",
    "model = pipeline.fit(train)\n",
    "\n",
    "# 예측\n",
    "predictions = model.transform(test)\n",
    "predictions.select(\"prediction\", target, \"features\").show(10)\n",
    "\n",
    "# RMSE\n",
    "evaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=target, metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "59f6e2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (spark_start)",
   "language": "python",
   "name": "spark_start"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
